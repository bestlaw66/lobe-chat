{
  "01-ai/Yi-1.5-34B-Chat-16K": {
    "description": "Yi-1.5 34B با نمونه‌های آموزشی غنی در کاربردهای صنعتی عملکرد برتری را ارائه می‌دهد."
  },
  "01-ai/Yi-1.5-9B-Chat-16K": {
    "description": "Yi-1.5 9B از 16K توکن پشتیبانی می‌کند و توانایی تولید زبان کارآمد و روانی را ارائه می‌دهد."
  },
  "360gpt-pro": {
    "description": "360GPT Pro به عنوان یکی از اعضای مهم مجموعه مدل‌های هوش مصنوعی 360، با توانایی پردازش متن کارآمد، نیازهای متنوع در زمینه‌های کاربرد زبان طبیعی را برآورده می‌کند و از درک متن‌های طولانی و مکالمات چند دور پشتیبانی می‌کند."
  },
  "360gpt-turbo": {
    "description": "360GPT Turbo توانایی محاسباتی و گفتگویی قوی را ارائه می‌دهد و دارای درک معنایی و کارایی تولید برجسته‌ای است و راه‌حل ایده‌آل برای دستیار هوشمند برای شرکت‌ها و توسعه‌دهندگان می‌باشد."
  },
  "360gpt-turbo-responsibility-8k": {
    "description": "360GPT Turbo Responsibility 8K بر امنیت معنایی و مسئولیت‌پذیری تأکید دارد و به‌طور خاص برای کاربردهایی که نیاز به امنیت محتوا دارند طراحی شده است و دقت و ثبات تجربه کاربری را تضمین می‌کند."
  },
  "360gpt2-pro": {
    "description": "360GPT2 Pro مدل پیشرفته پردازش زبان طبیعی است که توسط شرکت 360 معرفی شده و دارای قابلیت‌های عالی در تولید و درک متن است، به ویژه در زمینه تولید و خلاقیت، قادر به پردازش تبدیل‌های زبانی پیچیده و وظایف نقش‌آفرینی است."
  },
  "4.0Ultra": {
    "description": "Spark Ultra قدرتمندترین نسخه در سری مدل‌های بزرگ است که در حین ارتقاء زنجیره جستجوی آنلاین، توانایی درک و خلاصه‌سازی محتوای متنی را بهبود می‌بخشد. این یک راه‌حل جامع برای افزایش بهره‌وری اداری و پاسخگویی دقیق به نیازها است و محصول هوشمند پیشرو در صنعت است."
  },
  "Baichuan2-Turbo": {
    "description": "با استفاده از تکنیک‌های تقویت جستجو، پیوند کاملی بین مدل بزرگ و دانش حوزه و دانش وب ایجاد می‌کند. از بارگذاری انواع مستندات مانند PDF و Word و ورودی وب‌سایت پشتیبانی می‌کند و اطلاعات را به‌موقع و جامع به دست می‌آورد و نتایج خروجی دقیق و حرفه‌ای است."
  },
  "Baichuan3-Turbo": {
    "description": "بهینه‌سازی شده برای سناریوهای پرکاربرد شرکتی، بهبود قابل توجهی در عملکرد و قیمت مناسب. نسبت به مدل Baichuan2، تولید محتوا 20%، پرسش و پاسخ 17% و توانایی نقش‌آفرینی 40% بهبود یافته است. عملکرد کلی بهتر از GPT3.5 است."
  },
  "Baichuan3-Turbo-128k": {
    "description": "دارای پنجره زمینه فوق‌العاده طولانی 128K، بهینه‌سازی شده برای سناریوهای پرکاربرد شرکتی، بهبود قابل توجهی در عملکرد و قیمت مناسب. نسبت به مدل Baichuan2، تولید محتوا 20%، پرسش و پاسخ 17% و توانایی نقش‌آفرینی 40% بهبود یافته است. عملکرد کلی بهتر از GPT3.5 است."
  },
  "Baichuan4": {
    "description": "توانایی مدل در داخل کشور اول است و در وظایف چینی مانند دانشنامه، متن‌های طولانی و تولید خلاقانه از مدل‌های اصلی خارجی پیشی می‌گیرد. همچنین دارای قابلیت‌های چندرسانه‌ای پیشرفته است و در چندین معیار ارزیابی معتبر عملکرد خوبی دارد."
  },
  "ERNIE-3.5-128K": {
    "description": "مدل زبان بزرگ مقیاس بالا و پرچمدار خودساخته بایدو، که شامل حجم وسیعی از داده‌های متنی چینی و انگلیسی است و دارای توانایی‌های عمومی قوی است و می‌تواند نیازهای اکثر سناریوهای پرسش و پاسخ، تولید محتوا و کاربردهای افزونه را برآورده کند؛ از اتصال خودکار به افزونه جستجوی بایدو پشتیبانی می‌کند تا اطلاعات پرسش و پاسخ به‌روز باشد."
  },
  "ERNIE-3.5-8K": {
    "description": "مدل زبان بزرگ مقیاس بالا و پرچمدار خودساخته بایدو، که شامل حجم وسیعی از داده‌های متنی چینی و انگلیسی است و دارای توانایی‌های عمومی قوی است و می‌تواند نیازهای اکثر سناریوهای پرسش و پاسخ، تولید محتوا و کاربردهای افزونه را برآورده کند؛ از اتصال خودکار به افزونه جستجوی بایدو پشتیبانی می‌کند تا اطلاعات پرسش و پاسخ به‌روز باشد."
  },
  "ERNIE-3.5-8K-Preview": {
    "description": "مدل زبان بزرگ مقیاس بالا و پرچمدار خودساخته بایدو، که شامل حجم وسیعی از داده‌های متنی چینی و انگلیسی است و دارای توانایی‌های عمومی قوی است و می‌تواند نیازهای اکثر سناریوهای پرسش و پاسخ، تولید محتوا و کاربردهای افزونه را برآورده کند؛ از اتصال خودکار به افزونه جستجوی بایدو پشتیبانی می‌کند تا اطلاعات پرسش و پاسخ به‌روز باشد."
  },
  "ERNIE-4.0-8K-Latest": {
    "description": "مدل زبان بزرگ مقیاس فوق‌العاده و پرچمدار خودساخته بایدو، که نسبت به ERNIE 3.5 به‌طور کامل توانایی‌های مدل را ارتقا داده است و به‌طور گسترده‌ای برای سناریوهای پیچیده در زمینه‌های مختلف مناسب است؛ از اتصال خودکار به افزونه جستجوی بایدو پشتیبانی می‌کند تا اطلاعات پرسش و پاسخ به‌روز باشد."
  },
  "ERNIE-4.0-8K-Preview": {
    "description": "مدل زبان بزرگ مقیاس فوق‌العاده و پرچمدار خودساخته بایدو، که نسبت به ERNIE 3.5 به‌طور کامل توانایی‌های مدل را ارتقا داده است و به‌طور گسترده‌ای برای سناریوهای پیچیده در زمینه‌های مختلف مناسب است؛ از اتصال خودکار به افزونه جستجوی بایدو پشتیبانی می‌کند تا اطلاعات پرسش و پاسخ به‌روز باشد."
  },
  "ERNIE-4.0-Turbo-8K-Latest": {
    "description": "مدل زبان بزرگ مقیاس فوق‌العاده و پرچمدار خودساخته بایدو، که عملکرد کلی آن برجسته است و به‌طور گسترده‌ای برای سناریوهای پیچیده در زمینه‌های مختلف مناسب است؛ از اتصال خودکار به افزونه جستجوی بایدو پشتیبانی می‌کند تا اطلاعات پرسش و پاسخ به‌روز باشد. نسبت به ERNIE 4.0 در عملکرد بهتری دارد."
  },
  "ERNIE-4.0-Turbo-8K-Preview": {
    "description": "مدل زبان بزرگ مقیاس فوق‌العاده و پرچمدار خودساخته بایدو، که عملکرد کلی آن برجسته است و به‌طور گسترده‌ای برای سناریوهای پیچیده در زمینه‌های مختلف مناسب است؛ از اتصال خودکار به افزونه جستجوی بایدو پشتیبانی می‌کند تا اطلاعات پرسش و پاسخ به‌روز باشد. نسبت به ERNIE 4.0 در عملکرد بهتری دارد."
  },
  "ERNIE-Character-8K": {
    "description": "مدل زبان بزرگ با تمرکز بر سناریوهای خاص، مناسب برای NPCهای بازی، گفتگوی خدمات مشتری، نقش‌آفرینی در گفتگو و غیره، با سبک شخصیت واضح‌تر و یکپارچه‌تر و توانایی پیروی از دستورات قوی‌تر و عملکرد استنتاج بهتر."
  },
  "ERNIE-Lite-Pro-128K": {
    "description": "مدل زبان بزرگ سبک خودساخته بایدو، که به‌طور همزمان عملکرد مدل و کارایی استنتاج را بهینه‌سازی کرده است و عملکرد بهتری نسبت به ERNIE Lite دارد و برای استفاده در کارت‌های تسریع AI با قدرت محاسباتی پایین مناسب است."
  },
  "ERNIE-Speed-128K": {
    "description": "مدل زبان بزرگ خودساخته بایدو که در سال 2024 منتشر شده و دارای عملکرد بالا است، توانایی عمومی آن برجسته است و مناسب برای استفاده به عنوان مدل پایه برای تنظیم دقیق است و می‌تواند به‌خوبی مسائل خاص سناریوها را پردازش کند و در عین حال دارای عملکرد استنتاج بسیار خوبی است."
  },
  "ERNIE-Speed-Pro-128K": {
    "description": "مدل زبان بزرگ خودساخته بایدو که در سال 2024 منتشر شده و دارای عملکرد بالا است، توانایی عمومی آن برجسته است و عملکرد بهتری نسبت به ERNIE Speed دارد و مناسب برای استفاده به عنوان مدل پایه برای تنظیم دقیق است و می‌تواند به‌خوبی مسائل خاص سناریوها را پردازش کند و در عین حال دارای عملکرد استنتاج بسیار خوبی است."
  },
  "Gryphe/MythoMax-L2-13b": {
    "description": "MythoMax-L2 (13B) یک مدل نوآورانه است که برای کاربردهای چندگانه و وظایف پیچیده مناسب است."
  },
  "Max-32k": {
    "description": "Spark Max 32K دارای توانایی پردازش زمینه بزرگ است و توانایی درک زمینه و استدلال منطقی قوی‌تری دارد و از ورودی متن 32K توکن پشتیبانی می‌کند و برای خواندن اسناد طولانی، پرسش و پاسخ خصوصی و غیره مناسب است."
  },
  "Nous-Hermes-2-Mixtral-8x7B-DPO": {
    "description": "Hermes 2 Mixtral 8x7B DPO یک ادغام چندمدل بسیار انعطاف‌پذیر است که به منظور ارائه تجربه خلاقانه فوق‌العاده طراحی شده است."
  },
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO": {
    "description": "Nous Hermes 2 - Mixtral 8x7B-DPO (46.7B) یک مدل دستوری با دقت بالا است که برای محاسبات پیچیده مناسب است."
  },
  "NousResearch/Nous-Hermes-2-Yi-34B": {
    "description": "Nous Hermes-2 Yi (34B) خروجی زبان بهینه و امکانات کاربردی متنوع را ارائه می‌دهد."
  },
  "OpenGVLab/InternVL2-26B": {
    "description": "InternVL2 در انواع وظایف زبان بصری عملکرد برجسته‌ای را نشان می‌دهد، از جمله درک اسناد و نمودارها، درک متن‌های صحنه‌ای، OCR، حل مسائل علمی و ریاضی."
  },
  "OpenGVLab/InternVL2-Llama3-76B": {
    "description": "InternVL2 در انواع وظایف زبان بصری عملکرد برجسته‌ای را نشان می‌دهد، از جمله درک اسناد و نمودارها، درک متن‌های صحنه‌ای، OCR، حل مسائل علمی و ریاضی."
  },
  "Phi-3-medium-128k-instruct": {
    "description": "مدل Phi-3-medium مشابه، اما با اندازه زمینه بزرگتر که برای RAG یا تعداد کمی از نشانه‌ها مناسب است."
  },
  "Phi-3-medium-4k-instruct": {
    "description": "مدل 140 میلیارد پارامتری که کیفیت بهتری نسبت به Phi-3-mini دارد و بر روی داده‌های با کیفیت بالا و استدلالی متمرکز است."
  },
  "Phi-3-mini-128k-instruct": {
    "description": "مدل Phi-3-mini مشابه، اما با اندازه زمینه بزرگتر که برای RAG یا تعداد کمی از نشانه‌ها مناسب است."
  },
  "Phi-3-mini-4k-instruct": {
    "description": "کوچک‌ترین عضو خانواده Phi-3 که برای کیفیت و تأخیر کم بهینه‌سازی شده است."
  },
  "Phi-3-small-128k-instruct": {
    "description": "مدل Phi-3-small مشابه، اما با اندازه زمینه بزرگتر که برای RAG یا تعداد کمی از نشانه‌ها مناسب است."
  },
  "Phi-3-small-8k-instruct": {
    "description": "مدل 70 میلیارد پارامتری که کیفیت بهتری نسبت به Phi-3-mini دارد و بر روی داده‌های با کیفیت بالا و استدلالی متمرکز است."
  },
  "Phi-3.5-mini-instruct": {
    "description": "نسخه به‌روزرسانی شده مدل Phi-3-mini."
  },
  "Phi-3.5-vision-instrust": {
    "description": "نسخه به‌روزرسانی شده مدل Phi-3-vision."
  },
  "Pro-128k": {
    "description": "Spark Pro 128K دارای توانایی پردازش متن با زمینه بسیار بزرگ است و می‌تواند تا 128K اطلاعات زمینه‌ای را پردازش کند، به‌ویژه برای محتوای طولانی که نیاز به تحلیل کامل و پردازش ارتباطات منطقی طولانی دارد، می‌تواند در ارتباطات متنی پیچیده منطق روان و یکپارچه و پشتیبانی از ارجاعات متنوع را ارائه دهد."
  },
  "Pro/OpenGVLab/InternVL2-8B": {
    "description": "InternVL2 در انواع وظایف زبان بصری عملکرد برجسته‌ای را نشان می‌دهد، از جمله درک اسناد و نمودارها، درک متن‌های صحنه‌ای، OCR، حل مسائل علمی و ریاضی."
  },
  "Pro/Qwen/Qwen2-VL-7B-Instruct": {
    "description": "Qwen2-VL آخرین نسخه از مدل Qwen-VL است که در آزمون‌های درک بصری به عملکرد پیشرفته‌ای دست یافته است."
  },
  "Qwen/Qwen1.5-110B-Chat": {
    "description": "Qwen 1.5 Chat (110B) یک مدل گفتگویی با عملکرد بالا است که از سناریوهای گفتگوی پیچیده پشتیبانی می‌کند."
  },
  "Qwen/Qwen1.5-72B-Chat": {
    "description": "Qwen 1.5 Chat (72B) پاسخ‌های سریع و توانایی گفتگوی طبیعی را ارائه می‌دهد و برای محیط‌های چند زبانه مناسب است."
  },
  "Qwen/Qwen2-72B-Instruct": {
    "description": "Qwen 2 Instruct (72B) برای کاربردهای سطح شرکتی درک و پاسخ‌دهی دقیق به دستورات را ارائه می‌دهد."
  },
  "Qwen/Qwen2-VL-72B-Instruct": {
    "description": "Qwen2-VL آخرین نسخه از مدل Qwen-VL است که در آزمون‌های درک بصری به عملکرد پیشرفته‌ای دست یافته است."
  },
  "Qwen/Qwen2.5-14B-Instruct": {
    "description": "Qwen2.5 یک سری جدید از مدل‌های زبان بزرگ است که بهینه‌سازی پردازش وظایف دستوری را هدف قرار داده است."
  },
  "Qwen/Qwen2.5-32B-Instruct": {
    "description": "Qwen2.5 یک سری جدید از مدل‌های زبان بزرگ است که بهینه‌سازی پردازش وظایف دستوری را هدف قرار داده است."
  },
  "Qwen/Qwen2.5-72B-Instruct-128K": {
    "description": "Qwen2.5 یک سری جدید از مدل‌های زبان بزرگ است که دارای توانایی‌های درک و تولید قوی‌تری است."
  },
  "Qwen/Qwen2.5-72B-Instruct-Turbo": {
    "description": "Qwen2.5 یک سری جدید از مدل‌های زبانی بزرگ است که بهینه‌سازی پردازش وظایف دستوری را هدف قرار داده است."
  },
  "Qwen/Qwen2.5-7B-Instruct": {
    "description": "Qwen2.5 یک سری جدید از مدل‌های زبان بزرگ است که بهینه‌سازی پردازش وظایف دستوری را هدف قرار داده است."
  },
  "Qwen/Qwen2.5-7B-Instruct-Turbo": {
    "description": "Qwen2.5 یک سری جدید از مدل‌های زبانی بزرگ است که بهینه‌سازی پردازش وظایف دستوری را هدف قرار داده است."
  },
  "Qwen/Qwen2.5-Coder-7B-Instruct": {
    "description": "Qwen2.5-Coder بر کدنویسی تمرکز دارد."
  },
  "Qwen/Qwen2.5-Math-72B-Instruct": {
    "description": "Qwen2.5-Math بر حل مسائل در زمینه ریاضیات تمرکز دارد و پاسخ‌های حرفه‌ای برای مسائل دشوار ارائه می‌دهد."
  },
  "THUDM/glm-4-9b-chat": {
    "description": "نسخه منبع باز GLM-4 9B، تجربه گفتگویی بهینه‌سازی شده‌ای را برای برنامه‌های گفتگویی ارائه می‌دهد."
  },
  "abab5.5-chat": {
    "description": "مناسب برای سناریوهای تولید، از پردازش وظایف پیچیده و تولید متن کارآمد پشتیبانی می‌کند و برای کاربردهای حرفه‌ای مناسب است."
  },
  "abab5.5s-chat": {
    "description": "طراحی شده برای سناریوهای گفتگوی شخصیت‌های انسانی به زبان چینی و توانایی تولید گفتگوی با کیفیت بالا به زبان چینی را ارائه می‌دهد و برای طیف وسیعی از سناریوهای کاربردی مناسب است."
  },
  "abab6.5g-chat": {
    "description": "طراحی شده برای گفتگوی چند زبانه با شخصیت‌های انسانی، از تولید گفتگوی با کیفیت بالا به زبان انگلیسی و سایر زبان‌ها پشتیبانی می‌کند."
  },
  "abab6.5s-chat": {
    "description": "مناسب برای طیف وسیعی از وظایف پردازش زبان طبیعی، از جمله تولید متن، سیستم‌های گفتگویی و غیره."
  },
  "abab6.5t-chat": {
    "description": "بهینه‌سازی شده برای سناریوهای گفتگوی شخصیت‌های انسانی به زبان چینی و توانایی تولید گفتگوی روان و مطابق با عادات بیان چینی را ارائه می‌دهد."
  },
  "accounts/fireworks/models/firefunction-v1": {
    "description": "مدل فراخوانی تابع Fireworks، یک مدل منبع باز با قابلیت‌های عالی در اجرای دستورات و ویژگی‌های قابل تنظیم و باز."
  },
  "accounts/fireworks/models/firefunction-v2": {
    "description": "Fireworks شرکت جدیدترین مدل Firefunction-v2 را معرفی کرده است که یک مدل فراخوانی تابع با عملکرد عالی است، بر اساس Llama-3 توسعه یافته و از طریق بهینه‌سازی‌های فراوان، به‌ویژه برای فراخوانی تابع، گفتگو و پیروی از دستورات مناسب است."
  },
  "accounts/fireworks/models/firellava-13b": {
    "description": "fireworks-ai/FireLLaVA-13b یک مدل زبان بصری است که می‌تواند ورودی‌های تصویری و متنی را به طور همزمان دریافت کند و برای وظایف چندرسانه‌ای مناسب است."
  },
  "accounts/fireworks/models/llama-v3-70b-instruct": {
    "description": "مدل دستور Llama 3 70B، بهینه‌سازی شده برای مکالمات چند زبانه و درک زبان طبیعی، عملکردی بهتر از اکثر مدل‌های رقیب دارد."
  },
  "accounts/fireworks/models/llama-v3-70b-instruct-hf": {
    "description": "مدل دستور Llama 3 70B (نسخه HF)، با نتایج سازگار با پیاده‌سازی رسمی، مناسب برای وظایف پیروی از دستورات با کیفیت بالا است."
  },
  "accounts/fireworks/models/llama-v3-8b-instruct": {
    "description": "مدل دستور Llama 3 8B، بهینه‌سازی شده برای مکالمات و وظایف چند زبانه، عملکرد عالی و کارآمدی را ارائه می‌دهد."
  },
  "accounts/fireworks/models/llama-v3-8b-instruct-hf": {
    "description": "مدل دستور Llama 3 8B (نسخه HF)، با نتایج سازگار با پیاده‌سازی رسمی، دارای سازگاری بالا و قابلیت‌های چند پلتفرمی است."
  },
  "accounts/fireworks/models/llama-v3p1-405b-instruct": {
    "description": "مدل دستور Llama 3.1 405B، با پارامترهای فوق‌العاده بزرگ، مناسب برای وظایف پیچیده و پیروی از دستورات در سناریوهای بار سنگین است."
  },
  "accounts/fireworks/models/llama-v3p1-70b-instruct": {
    "description": "مدل دستور Llama 3.1 70B، قابلیت‌های عالی در درک و تولید زبان طبیعی را ارائه می‌دهد و انتخاب ایده‌آلی برای وظایف مکالمه و تحلیل است."
  },
  "accounts/fireworks/models/llama-v3p1-8b-instruct": {
    "description": "مدل دستور Llama 3.1 8B، بهینه‌سازی شده برای مکالمات چند زبانه، قادر به فراتر رفتن از اکثر مدل‌های منبع باز و بسته در معیارهای صنعتی رایج است."
  },
  "accounts/fireworks/models/llama-v3p2-11b-vision-instruct": {
    "description": "مدل استنتاج تصویر با تنظیم دستور 11B پارامتر متا. این مدل برای شناسایی بصری، استنتاج تصویر، توصیف تصویر و پاسخ به سوالات عمومی در مورد تصاویر بهینه‌سازی شده است. این مدل قادر به درک داده‌های بصری مانند نمودارها و گرافیک‌ها است و با تولید توصیف متنی از جزئیات تصویر، شکاف بین بصری و زبان را پر می‌کند."
  },
  "accounts/fireworks/models/llama-v3p2-1b-instruct": {
    "description": "مدل دستور Llama 3.2 1B یک مدل چند زبانه سبک است که توسط متا معرفی شده است. این مدل به منظور افزایش کارایی طراحی شده و در مقایسه با مدل‌های بزرگتر، بهبود قابل توجهی در تأخیر و هزینه ارائه می‌دهد. نمونه‌های استفاده از این مدل شامل جستجو و خلاصه‌سازی است."
  },
  "accounts/fireworks/models/llama-v3p2-3b-instruct": {
    "description": "مدل دستور Llama 3.2 3B یک مدل چند زبانه سبک است که توسط متا معرفی شده است. این مدل به منظور افزایش کارایی طراحی شده و در مقایسه با مدل‌های بزرگتر، بهبود قابل توجهی در تأخیر و هزینه ارائه می‌دهد. نمونه‌های استفاده از این مدل شامل پرسش و بازنویسی پیشنهادات و کمک به نوشتن است."
  },
  "accounts/fireworks/models/llama-v3p2-90b-vision-instruct": {
    "description": "مدل استنتاج تصویر با تنظیم دستور 90B پارامتر متا. این مدل برای شناسایی بصری، استنتاج تصویر، توصیف تصویر و پاسخ به سوالات عمومی در مورد تصاویر بهینه‌سازی شده است. این مدل قادر به درک داده‌های بصری مانند نمودارها و گرافیک‌ها است و با تولید توصیف متنی از جزئیات تصویر، شکاف بین بصری و زبان را پر می‌کند."
  },
  "accounts/fireworks/models/mixtral-8x22b-instruct": {
    "description": "مدل دستور Mixtral MoE 8x22B، با پارامترهای بزرگ و معماری چند متخصص، به طور جامع از پردازش کارآمد وظایف پیچیده پشتیبانی می‌کند."
  },
  "accounts/fireworks/models/mixtral-8x7b-instruct": {
    "description": "مدل دستور Mixtral MoE 8x7B، معماری چند متخصص برای پیروی و اجرای دستورات به طور کارآمد ارائه می‌دهد."
  },
  "accounts/fireworks/models/mixtral-8x7b-instruct-hf": {
    "description": "مدل دستور Mixtral MoE 8x7B (نسخه HF)، عملکردی مطابق با پیاده‌سازی رسمی، مناسب برای انواع سناریوهای کارآمد است."
  },
  "accounts/fireworks/models/mythomax-l2-13b": {
    "description": "مدل MythoMax L2 13B، با تکنیک‌های ادغام نوآورانه، در داستان‌گویی و نقش‌آفرینی مهارت دارد."
  },
  "accounts/fireworks/models/phi-3-vision-128k-instruct": {
    "description": "Phi-3-Vision-128K-Instruct یک مدل چندرسانه‌ای پیشرفته و سبک است که بر اساس مجموعه داده‌هایی از جمله داده‌های ترکیبی و وب‌سایت‌های عمومی ساخته شده است و بر روی داده‌های با کیفیت بسیار بالا و با تمرکز بر استنتاج، شامل متن و بصری، تمرکز دارد. این مدل متعلق به سری مدل‌های Phi-3 است و نسخه چندرسانه‌ای آن از طول زمینه 128K (به صورت توکن) پشتیبانی می‌کند. این مدل از یک فرآیند تقویت دقیق عبور کرده و ترکیبی از تنظیم دقیق نظارتی و بهینه‌سازی ترجیحات مستقیم را برای اطمینان از پیروی دقیق از دستورات و اقدامات ایمنی قوی تضمین می‌کند."
  },
  "accounts/fireworks/models/qwen2p5-72b-instruct": {
    "description": "Qwen2.5 یک سری مدل‌های زبان است که تنها شامل دیکودر است و توسط تیم Qwen آلی‌بابا توسعه یافته است. این مدل‌ها اندازه‌های مختلفی از جمله 0.5B، 1.5B، 3B، 7B، 14B، 32B و 72B را ارائه می‌دهند و دارای دو نوع متغیر، نسخه پایه (base) و نسخه دستور (instruct) هستند."
  },
  "accounts/fireworks/models/starcoder-16b": {
    "description": "مدل StarCoder 15.5B، از وظایف برنامه‌نویسی پیشرفته پشتیبانی می‌کند و توانایی‌های چند زبانه آن برای تولید و درک کدهای پیچیده مناسب است."
  },
  "accounts/fireworks/models/starcoder-7b": {
    "description": "مدل StarCoder 7B، برای بیش از 80 زبان برنامه‌نویسی آموزش دیده و دارای قابلیت‌های عالی در پر کردن کد و درک زمینه است."
  },
  "accounts/yi-01-ai/models/yi-large": {
    "description": "مدل Yi-Large، با قابلیت‌های عالی در پردازش چند زبانه، می‌تواند برای انواع وظایف تولید و درک زبان استفاده شود."
  },
  "ai21-jamba-1.5-large": {
    "description": "مدلی با 398B پارامتر (94B فعال) چند زبانه که پنجره زمینه 256K طولانی، فراخوانی توابع، خروجی ساختاری و تولید مبتنی بر واقعیت را ارائه می‌دهد."
  },
  "ai21-jamba-1.5-mini": {
    "description": "مدلی با 52B پارامتر (12B فعال) چند زبانه که پنجره زمینه 256K طولانی، فراخوانی توابع، خروجی ساختاری و تولید مبتنی بر واقعیت را ارائه می‌دهد."
  },
  "anthropic.claude-3-5-sonnet-20240620-v1:0": {
    "description": "Claude 3.5 Sonnet استانداردهای صنعتی را ارتقا داده و عملکردی فراتر از مدل‌های رقیب و Claude 3 Opus دارد و در ارزیابی‌های گسترده‌ای عملکرد خوبی از خود نشان می‌دهد و در عین حال دارای سرعت و هزینه مدل‌های سطح متوسط ما است."
  },
  "anthropic.claude-3-haiku-20240307-v1:0": {
    "description": "Claude 3 Haiku سریع‌ترین و فشرده‌ترین مدل Anthropic است که سرعت پاسخ‌دهی نزدیک به آنی را ارائه می‌دهد. این مدل می‌تواند به سرعت به پرسش‌ها و درخواست‌های ساده پاسخ دهد. مشتریان قادر خواهند بود تجربه‌ای بدون درز از تعامل انسانی را با AI بسازند. Claude 3 Haiku می‌تواند تصاویر را پردازش کرده و خروجی متنی بازگرداند و دارای یک پنجره زمینه 200K است."
  },
  "anthropic.claude-3-opus-20240229-v1:0": {
    "description": "Claude 3 Opus قدرتمندترین مدل AI Anthropic است که دارای عملکرد پیشرفته در وظایف بسیار پیچیده است. این مدل می‌تواند به ورودی‌های باز و صحنه‌های ناشناخته پاسخ دهد و دارای روانی و درک انسانی فوق‌العاده‌ای است. Claude 3 Opus مرزهای ممکن در AI تولیدی را نشان می‌دهد. Claude 3 Opus می‌تواند تصاویر را پردازش کرده و خروجی متنی بازگرداند و دارای یک پنجره زمینه 200K است."
  },
  "anthropic.claude-3-sonnet-20240229-v1:0": {
    "description": "Claude 3 Sonnet از Anthropic تعادل ایده‌آلی بین هوش و سرعت برقرار کرده است - به‌ویژه برای بارهای کاری شرکتی مناسب است. این مدل بیشترین کارایی را با قیمتی کمتر از رقبای خود ارائه می‌دهد و به عنوان یک مدل اصلی قابل اعتماد و با دوام طراحی شده است که برای استقرار AI در مقیاس بزرگ مناسب است. Claude 3 Sonnet می‌تواند تصاویر را پردازش کرده و خروجی متنی بازگرداند و دارای یک پنجره زمینه 200K است."
  },
  "anthropic.claude-instant-v1": {
    "description": "مدلی سریع، اقتصادی و همچنان بسیار توانمند که می‌تواند مجموعه‌ای از وظایف از جمله مکالمات روزمره، تحلیل متن، خلاصه‌سازی و پرسش و پاسخ مستندات را پردازش کند."
  },
  "anthropic.claude-v2": {
    "description": "مدلی با توانایی‌های بالا که در انجام وظایف گسترده از مکالمات پیچیده و تولید محتوای خلاقانه تا پیروی دقیق از دستورات عملکرد خوبی دارد."
  },
  "anthropic.claude-v2:1": {
    "description": "نسخه به‌روزرسانی شده Claude 2 که دارای دو برابر پنجره زمینه و بهبود در قابلیت اطمینان، نرخ توهم و دقت مبتنی بر شواهد در زمینه‌های طولانی و RAG است."
  },
  "anthropic/claude-3-haiku": {
    "description": "Claude 3 Haiku سریع‌ترین و فشرده‌ترین مدل Anthropic است که به منظور ارائه پاسخ‌های تقریباً آنی طراحی شده است. این مدل دارای عملکرد سریع و دقیق در هدایت است."
  },
  "anthropic/claude-3-opus": {
    "description": "Claude 3 Opus قدرتمندترین مدل Anthropic برای پردازش وظایف بسیار پیچیده است. این مدل در عملکرد، هوش، روانی و درک به‌طور برجسته‌ای عمل می‌کند."
  },
  "anthropic/claude-3.5-sonnet": {
    "description": "Claude 3.5 Sonnet قابلیت‌هایی فراتر از Opus و سرعتی بالاتر از Sonnet را ارائه می‌دهد و در عین حال با قیمت مشابه Sonnet عرضه می‌شود. Sonnet به‌ویژه در برنامه‌نویسی، علم داده، پردازش بصری و وظایف نمایندگی مهارت دارد."
  },
  "aya": {
    "description": "Aya 23 یک مدل چند زبانه است که توسط Cohere ارائه شده و از 23 زبان پشتیبانی می‌کند و برای کاربردهای زبانی متنوع مناسب است."
  },
  "aya:35b": {
    "description": "Aya 23 یک مدل چند زبانه است که توسط Cohere ارائه شده و از 23 زبان پشتیبانی می‌کند و برای کاربردهای زبانی متنوع مناسب است."
  },
  "charglm-3": {
    "description": "CharGLM-3 به طور خاص برای نقش‌آفرینی و همراهی عاطفی طراحی شده است و از حافظه چند دور طولانی و گفت‌وگوهای شخصی‌سازی شده پشتیبانی می‌کند و کاربردهای گسترده‌ای دارد."
  },
  "chatgpt-4o-latest": {
    "description": "ChatGPT-4o یک مدل پویا است که به‌طور زنده به‌روزرسانی می‌شود تا آخرین نسخه را حفظ کند. این مدل ترکیبی از درک و توانایی تولید زبان قوی است و برای سناریوهای کاربردی بزرگ مقیاس، از جمله خدمات مشتری، آموزش و پشتیبانی فنی مناسب است."
  },
  "claude-2.0": {
    "description": "Claude 2 پیشرفت‌های کلیدی در قابلیت‌های شرکتی را ارائه می‌دهد، از جمله زمینه 200K توکن پیشرو در صنعت، کاهش قابل توجه نرخ توهم مدل، راهنمای سیستم و یک ویژگی آزمایشی جدید: فراخوانی ابزار."
  },
  "claude-2.1": {
    "description": "Claude 2 پیشرفت‌های کلیدی در قابلیت‌های شرکتی را ارائه می‌دهد، از جمله زمینه 200K توکن پیشرو در صنعت، کاهش قابل توجه نرخ توهم مدل، راهنمای سیستم و یک ویژگی آزمایشی جدید: فراخوانی ابزار."
  },
  "claude-3-5-sonnet-20240620": {
    "description": "Claude 3.5 Sonnet قابلیت‌هایی فراتر از Opus و سرعتی سریع‌تر از Sonnet را ارائه می‌دهد، در حالی که قیمت مشابهی با Sonnet دارد. Sonnet به ویژه در برنامه‌نویسی، علم داده، پردازش بصری و وظایف نمایندگی مهارت دارد."
  },
  "claude-3-5-sonnet-20241022": {
    "description": "Claude 3.5 Sonnet قابلیت‌هایی فراتر از Opus و سرعتی سریع‌تر از Sonnet را ارائه می‌دهد، در حالی که قیمت مشابهی با Sonnet دارد. Sonnet به ویژه در برنامه‌نویسی، علم داده، پردازش بصری و وظایف نمایندگی مهارت دارد."
  },
  "claude-3-haiku-20240307": {
    "description": "Claude 3 Haiku سریع‌ترین و فشرده‌ترین مدل Anthropic است که به منظور دستیابی به پاسخ‌های تقریباً آنی طراحی شده است. این مدل دارای عملکرد سریع و دقیق در هدایت است."
  },
  "claude-3-opus-20240229": {
    "description": "Claude 3 Opus قدرتمندترین مدل Anthropic برای پردازش وظایف بسیار پیچیده است. این مدل در عملکرد، هوش، روانی و درک فوق‌العاده است."
  },
  "claude-3-sonnet-20240229": {
    "description": "Claude 3 Sonnet تعادل ایده‌آلی بین هوش و سرعت برای بارهای کاری شرکتی ارائه می‌دهد. این مدل با قیمت پایین‌تر، حداکثر کارایی را ارائه می‌دهد و برای استقرار در مقیاس بزرگ مناسب است."
  },
  "codegeex-4": {
    "description": "CodeGeeX-4 یک دستیار برنامه‌نویسی هوش مصنوعی قوی است که از زبان‌های برنامه‌نویسی مختلف پشتیبانی می‌کند و به سوالات هوشمند و تکمیل کد پاسخ می‌دهد و کارایی توسعه را افزایش می‌دهد."
  },
  "codegemma": {
    "description": "CodeGemma یک مدل زبانی سبک است که به طور خاص برای وظایف مختلف برنامه‌نویسی طراحی شده و از تکرار و ادغام سریع پشتیبانی می‌کند."
  },
  "codegemma:2b": {
    "description": "CodeGemma یک مدل زبانی سبک است که به طور خاص برای وظایف مختلف برنامه‌نویسی طراحی شده و از تکرار و ادغام سریع پشتیبانی می‌کند."
  },
  "codellama": {
    "description": "Code Llama مدلی است که بر روی تولید و بحث کد تمرکز دارد و از پشتیبانی گسترده زبان‌های برنامه‌نویسی برخوردار است و برای محیط‌های توسعه‌دهنده مناسب است."
  },
  "codellama:13b": {
    "description": "Code Llama مدلی است که بر روی تولید و بحث کد تمرکز دارد و از پشتیبانی گسترده زبان‌های برنامه‌نویسی برخوردار است و برای محیط‌های توسعه‌دهنده مناسب است."
  },
  "codellama:34b": {
    "description": "Code Llama مدلی است که بر روی تولید و بحث کد تمرکز دارد و از پشتیبانی گسترده زبان‌های برنامه‌نویسی برخوردار است و برای محیط‌های توسعه‌دهنده مناسب است."
  },
  "codellama:70b": {
    "description": "Code Llama مدلی است که بر روی تولید و بحث کد تمرکز دارد و از پشتیبانی گسترده زبان‌های برنامه‌نویسی برخوردار است و برای محیط‌های توسعه‌دهنده مناسب است."
  },
  "codeqwen": {
    "description": "CodeQwen1.5 یک مدل زبانی بزرگ است که بر اساس داده‌های کد فراوان آموزش دیده و به طور خاص برای حل وظایف پیچیده برنامه‌نویسی طراحی شده است."
  },
  "codestral": {
    "description": "Codestral اولین مدل کد Mistral AI است که پشتیبانی عالی برای وظایف تولید کد ارائه می‌دهد."
  },
  "codestral-latest": {
    "description": "Codestral یک مدل تولیدی پیشرفته است که بر روی تولید کد تمرکز دارد و وظایف پر کردن میانی و تکمیل کد را بهینه‌سازی کرده است."
  },
  "cognitivecomputations/dolphin-mixtral-8x22b": {
    "description": "Dolphin Mixtral 8x22B مدلی است که برای پیروی از دستورات، مکالمه و برنامه‌نویسی طراحی شده است."
  },
  "cohere-command-r": {
    "description": "Command R یک مدل تولیدی قابل گسترش است که برای RAG و استفاده از ابزارها طراحی شده است و به شرکت‌ها امکان می‌دهد AI در سطح تولید را پیاده‌سازی کنند."
  },
  "cohere-command-r-plus": {
    "description": "Command R+ یک مدل بهینه‌سازی شده RAG پیشرفته است که برای بارهای کاری در سطح شرکتی طراحی شده است."
  },
  "command-r": {
    "description": "Command R یک مدل LLM بهینه‌سازی شده برای وظایف گفتگویی و زمینه‌های طولانی است که به ویژه برای تعاملات پویا و مدیریت دانش مناسب است."
  },
  "command-r-plus": {
    "description": "Command R+ یک مدل زبانی بزرگ با عملکرد بالا است که به طور خاص برای سناریوهای واقعی کسب و کار و کاربردهای پیچیده طراحی شده است."
  },
  "databricks/dbrx-instruct": {
    "description": "DBRX Instruct توانایی‌های پردازش دستورات با قابلیت اطمینان بالا را ارائه می‌دهد و از کاربردهای چند صنعتی پشتیبانی می‌کند."
  },
  "deepseek-ai/DeepSeek-V2.5": {
    "description": "DeepSeek V2.5 ویژگی‌های برجسته نسخه‌های قبلی را جمع‌آوری کرده و توانایی‌های عمومی و کدنویسی را تقویت کرده است."
  },
  "deepseek-ai/deepseek-llm-67b-chat": {
    "description": "DeepSeek LLM Chat (67B) یک مدل AI نوآورانه است که توانایی‌های عمیق درک زبان و تعامل را ارائه می‌دهد."
  },
  "deepseek-chat": {
    "description": "مدل جدید متن‌باز که توانایی‌های عمومی و کد را ترکیب می‌کند، نه تنها توانایی‌های گفتگوی عمومی مدل Chat را حفظ کرده و قدرت پردازش کد مدل Coder را بهبود می‌بخشد، بلکه به ترجیحات انسانی نیز بهتر هم‌راستا شده است. علاوه بر این، DeepSeek-V2.5 در وظایف نوشتن، پیروی از دستورالعمل‌ها و چندین زمینه دیگر نیز بهبودهای قابل توجهی را به ارمغان آورده است."
  },
  "deepseek-coder-v2": {
    "description": "DeepSeek Coder V2 یک مدل کد باز مختلط است که در وظایف کد عملکرد عالی دارد و با GPT4-Turbo قابل مقایسه است."
  },
  "deepseek-coder-v2:236b": {
    "description": "DeepSeek Coder V2 یک مدل کد باز مختلط است که در وظایف کد عملکرد عالی دارد و با GPT4-Turbo قابل مقایسه است."
  },
  "deepseek-v2": {
    "description": "DeepSeek V2 یک مدل زبانی Mixture-of-Experts کارآمد است که برای نیازهای پردازش اقتصادی مناسب است."
  },
  "deepseek-v2:236b": {
    "description": "DeepSeek V2 236B یک مدل کد طراحی شده توسط DeepSeek است که توانایی تولید کد قوی را ارائه می‌دهد."
  },
  "deepseek/deepseek-chat": {
    "description": "مدل جدید متن باز که توانایی‌های عمومی و کد را ترکیب می‌کند، نه تنها قابلیت‌های گفتگوی عمومی مدل Chat را حفظ کرده و توانایی‌های قوی پردازش کد مدل Coder را بهبود می‌بخشد، بلکه به‌خوبی با ترجیحات انسانی هم‌راستا شده است. علاوه بر این، DeepSeek-V2.5 در وظایف نوشتن، پیروی از دستورات و چندین زمینه دیگر نیز به‌طور قابل توجهی بهبود یافته است."
  },
  "emohaa": {
    "description": "Emohaa یک مدل روانشناختی است که دارای توانایی مشاوره حرفه‌ای است و به کاربران در درک مسائل عاطفی کمک می‌کند."
  },
  "gemini-1.0-pro-001": {
    "description": "Gemini 1.0 Pro 001 (تنظیم) عملکرد پایدار و قابل تنظیمی را ارائه می‌دهد و انتخاب ایده‌آلی برای راه‌حل‌های وظایف پیچیده است."
  },
  "gemini-1.0-pro-002": {
    "description": "Gemini 1.0 Pro 002 (تنظیم) پشتیبانی چندرسانه‌ای فوق‌العاده‌ای را ارائه می‌دهد و بر روی حل مؤثر وظایف پیچیده تمرکز دارد."
  },
  "gemini-1.0-pro-latest": {
    "description": "Gemini 1.0 Pro مدل AI با عملکرد بالا از Google است که به طور خاص برای گسترش در وظایف وسیع طراحی شده است."
  },
  "gemini-1.5-flash-001": {
    "description": "Gemini 1.5 Flash 001 یک مدل چندرسانه‌ای کارآمد است که از گسترش کاربردهای وسیع پشتیبانی می‌کند."
  },
  "gemini-1.5-flash-002": {
    "description": "Gemini 1.5 Flash 002 یک مدل چندرسانه‌ای کارآمد است که از گسترش کاربردهای وسیع پشتیبانی می‌کند."
  },
  "gemini-1.5-flash-8b-exp-0924": {
    "description": "Gemini 1.5 Flash 8B 0924 جدیدترین مدل آزمایشی است که در موارد متنی و چندرسانه‌ای بهبودهای قابل توجهی در عملکرد دارد."
  },
  "gemini-1.5-flash-exp-0827": {
    "description": "Gemini 1.5 Flash 0827 توانایی پردازش چندرسانه‌ای بهینه‌سازی شده‌ای را ارائه می‌دهد که برای انواع سناریوهای وظیفه پیچیده مناسب است."
  },
  "gemini-1.5-flash-latest": {
    "description": "Gemini 1.5 Flash جدیدترین مدل AI چندرسانه‌ای Google است که دارای توانایی پردازش سریع بوده و از ورودی‌های متنی، تصویری و ویدیویی پشتیبانی می‌کند و برای گسترش کارآمد در انواع وظایف مناسب است."
  },
  "gemini-1.5-pro-001": {
    "description": "Gemini 1.5 Pro 001 یک راه‌حل AI چندرسانه‌ای قابل گسترش است که از وظایف پیچیده وسیع پشتیبانی می‌کند."
  },
  "gemini-1.5-pro-002": {
    "description": "Gemini 1.5 Pro 002 جدیدترین مدل آماده تولید است که خروجی با کیفیت بالاتری را ارائه می‌دهد و به ویژه در زمینه‌های ریاضی، زمینه‌های طولانی و وظایف بصری بهبودهای قابل توجهی دارد."
  },
  "gemini-1.5-pro-exp-0801": {
    "description": "Gemini 1.5 Pro 0801 توانایی پردازش چندرسانه‌ای فوق‌العاده‌ای را ارائه می‌دهد و برای توسعه برنامه‌ها انعطاف‌پذیری بیشتری را به ارمغان می‌آورد."
  },
  "gemini-1.5-pro-exp-0827": {
    "description": "Gemini 1.5 Pro 0827 با استفاده از جدیدترین تکنیک‌های بهینه‌سازی، توانایی پردازش داده‌های چندرسانه‌ای کارآمدتری را به ارمغان می‌آورد."
  },
  "gemini-1.5-pro-latest": {
    "description": "Gemini 1.5 Pro از حداکثر 2 میلیون توکن پشتیبانی می‌کند و انتخاب ایده‌آلی برای مدل‌های چندرسانه‌ای متوسط است که برای پشتیبانی چندجانبه از وظایف پیچیده مناسب است."
  },
  "gemma-7b-it": {
    "description": "Gemma 7B برای پردازش وظایف متوسط و کوچک مناسب است و از نظر هزینه به صرفه است."
  },
  "gemma2": {
    "description": "Gemma 2 یک مدل کارآمد است که توسط گوگل ارائه شده و شامل انواع مختلفی از سناریوهای کاربردی از برنامه‌های کوچک تا پردازش داده‌های پیچیده می‌باشد."
  },
  "gemma2-9b-it": {
    "description": "Gemma 2 9B مدلی است که برای وظایف خاص و ادغام ابزارها بهینه‌سازی شده است."
  },
  "gemma2:27b": {
    "description": "Gemma 2 یک مدل کارآمد است که توسط گوگل ارائه شده و شامل انواع مختلفی از سناریوهای کاربردی از برنامه‌های کوچک تا پردازش داده‌های پیچیده می‌باشد."
  },
  "gemma2:2b": {
    "description": "Gemma 2 مدلی است که توسط Google ارائه شده و برای طیف وسیعی از کاربردها از برنامه‌های کوچک تا پردازش داده‌های پیچیده بهینه‌سازی شده است."
  },
  "general": {
    "description": "Spark Lite یک مدل زبان بزرگ سبک است که دارای تأخیر بسیار کم و توانایی پردازش کارآمد است و به‌طور کامل رایگان و باز است و از قابلیت جستجوی آنلاین در زمان واقعی پشتیبانی می‌کند. ویژگی پاسخ سریع آن باعث می‌شود که در کاربردهای استنتاج و میکرو تنظیم مدل در دستگاه‌های با قدرت محاسباتی پایین عملکرد برجسته‌ای داشته باشد و تجربه هوشمند و مقرون به صرفه‌ای را برای کاربران فراهم کند، به‌ویژه در زمینه‌های پرسش و پاسخ، تولید محتوا و جستجو."
  },
  "generalv3": {
    "description": "Spark Pro یک مدل زبان بزرگ با عملکرد بالا است که برای زمینه‌های حرفه‌ای بهینه‌سازی شده و بر ریاضیات، برنامه‌نویسی، پزشکی، آموزش و چندین زمینه دیگر تمرکز دارد و از جستجوی آنلاین و افزونه‌های داخلی مانند آب و هوا و تاریخ پشتیبانی می‌کند. مدل بهینه‌سازی شده آن در پرسش و پاسخ پیچیده، درک زبان و تولید متن در سطوح بالا عملکرد برجسته و کارایی بالایی را نشان می‌دهد و انتخاب ایده‌آلی برای سناریوهای کاربردی حرفه‌ای است."
  },
  "generalv3.5": {
    "description": "Spark Max به عنوان جامع‌ترین نسخه، از جستجوی آنلاین و بسیاری از افزونه‌های داخلی پشتیبانی می‌کند. توانایی‌های هسته‌ای به‌طور کامل بهینه‌سازی شده و تنظیم نقش‌های سیستمی و قابلیت‌های فراخوانی توابع، عملکرد آن را در انواع سناریوهای کاربردی پیچیده به‌طور قابل توجهی بهبود می‌بخشد."
  },
  "glm-4": {
    "description": "GLM-4 نسخه قدیمی پرچمدار منتشر شده در ژانویه 2024 است که اکنون با GLM-4-0520 قوی‌تر جایگزین شده است."
  },
  "glm-4-0520": {
    "description": "GLM-4-0520 جدیدترین نسخه مدل است که به طور خاص برای وظایف بسیار پیچیده و متنوع طراحی شده و عملکرد فوق‌العاده‌ای دارد."
  },
  "glm-4-air": {
    "description": "GLM-4-Air نسخه‌ای با قیمت مناسب است که عملکردی نزدیک به GLM-4 ارائه می‌دهد و سرعت بالا و قیمت مقرون به صرفه‌ای دارد."
  },
  "glm-4-airx": {
    "description": "GLM-4-AirX نسخه کارآمد GLM-4-Air است که سرعت استدلال آن به 2.6 برابر می‌رسد."
  },
  "glm-4-alltools": {
    "description": "GLM-4-AllTools یک مدل هوشمند چندمنظوره است که برای پشتیبانی از برنامه‌ریزی دستورات پیچیده و فراخوانی ابزارها بهینه‌سازی شده است، مانند مرور وب، تفسیر کد و تولید متن، مناسب برای اجرای چندوظیفه‌ای."
  },
  "glm-4-flash": {
    "description": "GLM-4-Flash انتخاب ایده‌آلی برای پردازش وظایف ساده است، سریع‌ترین و رایگان."
  },
  "glm-4-flashx": {
    "description": "GLM-4-FlashX نسخه تقویت شده Flash است که سرعت استدلال فوق‌العاده‌ای دارد."
  },
  "glm-4-long": {
    "description": "GLM-4-Long از ورودی‌های متنی فوق‌العاده طولانی پشتیبانی می‌کند و برای وظایف حافظه‌ای و پردازش اسناد بزرگ مناسب است."
  },
  "glm-4-plus": {
    "description": "GLM-4-Plus به عنوان پرچمدار هوش بالا، دارای توانایی‌های قوی در پردازش متن‌های طولانی و وظایف پیچیده است و عملکرد آن به طور کلی بهبود یافته است."
  },
  "glm-4v": {
    "description": "GLM-4V دارای توانایی‌های قوی در درک و استدلال بصری است و از انواع وظایف بصری پشتیبانی می‌کند."
  },
  "glm-4v-plus": {
    "description": "GLM-4V-Plus دارای توانایی درک محتوای ویدئویی و چند تصویر است و برای وظایف چندرسانه‌ای مناسب است."
  },
  "google/gemini-flash-1.5": {
    "description": "Gemini 1.5 Flash قابلیت‌های پردازش چندرسانه‌ای بهینه‌سازی شده را ارائه می‌دهد و برای انواع سناریوهای پیچیده مناسب است."
  },
  "google/gemini-pro-1.5": {
    "description": "Gemini 1.5 Pro با ترکیب جدیدترین تکنیک‌های بهینه‌سازی، قابلیت‌های پردازش داده‌های چندرسانه‌ای کارآمدتری را ارائه می‌دهد."
  },
  "google/gemma-2-27b-it": {
    "description": "Gemma 2 ادامه‌دهنده طراحی سبک و کارآمد است."
  },
  "google/gemma-2-2b-it": {
    "description": "مدل تنظیم دستور سبک گوگل"
  },
  "google/gemma-2-9b-it": {
    "description": "Gemma 2 یک سری مدل‌های متنی سبک و متن باز از گوگل است."
  },
  "google/gemma-2-9b-it:free": {
    "description": "Gemma 2 یک سری مدل‌های متنی سبک و متن باز از گوگل است."
  },
  "google/gemma-2b-it": {
    "description": "Gemma Instruct (2B) توانایی‌های پایه‌ای پردازش دستورات را ارائه می‌دهد و برای کاربردهای سبک مناسب است."
  },
  "gpt-3.5-turbo": {
    "description": "GPT 3.5 Turbo، مناسب برای انواع وظایف تولید و درک متن، در حال حاضر به gpt-3.5-turbo-0125 اشاره دارد."
  },
  "gpt-3.5-turbo-0125": {
    "description": "GPT 3.5 Turbo، مناسب برای انواع وظایف تولید و درک متن، در حال حاضر به gpt-3.5-turbo-0125 اشاره دارد."
  },
  "gpt-3.5-turbo-1106": {
    "description": "GPT 3.5 Turbo، مناسب برای انواع وظایف تولید و درک متن، در حال حاضر به gpt-3.5-turbo-0125 اشاره دارد."
  },
  "gpt-3.5-turbo-instruct": {
    "description": "GPT 3.5 Turbo، مناسب برای انواع وظایف تولید و درک متن، در حال حاضر به gpt-3.5-turbo-0125 اشاره دارد."
  },
  "gpt-4": {
    "description": "GPT-4 یک پنجره زمینه بزرگتر ارائه می‌دهد که می‌تواند ورودی‌های متنی طولانی‌تری را پردازش کند و برای سناریوهایی که نیاز به ادغام اطلاعات گسترده و تحلیل داده‌ها دارند، مناسب است."
  },
  "gpt-4-0125-preview": {
    "description": "مدل جدید GPT-4 Turbo دارای قابلیت‌های بصری است. اکنون، درخواست‌های بصری می‌توانند با استفاده از الگوی JSON و فراخوانی توابع انجام شوند. GPT-4 Turbo یک نسخه بهبود یافته است که پشتیبانی مقرون به صرفه‌ای برای وظایف چندرسانه‌ای ارائه می‌دهد. این مدل تعادل خوبی بین دقت و کارایی برقرار می‌کند و برای برنامه‌هایی که نیاز به تعامل زنده دارند، مناسب است."
  },
  "gpt-4-0613": {
    "description": "GPT-4 یک پنجره زمینه بزرگتر ارائه می‌دهد که می‌تواند ورودی‌های متنی طولانی‌تری را پردازش کند و برای سناریوهایی که نیاز به ادغام اطلاعات گسترده و تحلیل داده‌ها دارند، مناسب است."
  },
  "gpt-4-1106-preview": {
    "description": "مدل جدید GPT-4 Turbo دارای قابلیت‌های بصری است. اکنون، درخواست‌های بصری می‌توانند با استفاده از الگوی JSON و فراخوانی توابع انجام شوند. GPT-4 Turbo یک نسخه بهبود یافته است که پشتیبانی مقرون به صرفه‌ای برای وظایف چندرسانه‌ای ارائه می‌دهد. این مدل تعادل خوبی بین دقت و کارایی برقرار می‌کند و برای برنامه‌هایی که نیاز به تعامل زنده دارند، مناسب است."
  },
  "gpt-4-1106-vision-preview": {
    "description": "مدل جدید GPT-4 Turbo دارای قابلیت‌های بصری است. اکنون، درخواست‌های بصری می‌توانند با استفاده از الگوی JSON و فراخوانی توابع انجام شوند. GPT-4 Turbo یک نسخه بهبود یافته است که پشتیبانی مقرون به صرفه‌ای برای وظایف چندرسانه‌ای ارائه می‌دهد. این مدل تعادل خوبی بین دقت و کارایی برقرار می‌کند و برای برنامه‌هایی که نیاز به تعامل زنده دارند، مناسب است."
  },
  "gpt-4-32k": {
    "description": "GPT-4 یک پنجره زمینه بزرگتر ارائه می‌دهد که می‌تواند ورودی‌های متنی طولانی‌تری را پردازش کند و برای سناریوهایی که نیاز به ادغام اطلاعات گسترده و تحلیل داده‌ها دارند، مناسب است."
  },
  "gpt-4-32k-0613": {
    "description": "GPT-4 یک پنجره زمینه بزرگتر ارائه می‌دهد که می‌تواند ورودی‌های متنی طولانی‌تری را پردازش کند و برای سناریوهایی که نیاز به ادغام اطلاعات گسترده و تحلیل داده‌ها دارند، مناسب است."
  },
  "gpt-4-turbo": {
    "description": "مدل جدید GPT-4 Turbo دارای قابلیت‌های بصری است. اکنون، درخواست‌های بصری می‌توانند با استفاده از الگوی JSON و فراخوانی توابع انجام شوند. GPT-4 Turbo یک نسخه بهبود یافته است که پشتیبانی مقرون به صرفه‌ای برای وظایف چندرسانه‌ای ارائه می‌دهد. این مدل تعادل خوبی بین دقت و کارایی برقرار می‌کند و برای برنامه‌هایی که نیاز به تعامل زنده دارند، مناسب است."
  },
  "gpt-4-turbo-2024-04-09": {
    "description": "مدل جدید GPT-4 Turbo دارای قابلیت‌های بصری است. اکنون، درخواست‌های بصری می‌توانند با استفاده از الگوی JSON و فراخوانی توابع انجام شوند. GPT-4 Turbo یک نسخه بهبود یافته است که پشتیبانی مقرون به صرفه‌ای برای وظایف چندرسانه‌ای ارائه می‌دهد. این مدل تعادل خوبی بین دقت و کارایی برقرار می‌کند و برای برنامه‌هایی که نیاز به تعامل زنده دارند، مناسب است."
  },
  "gpt-4-turbo-preview": {
    "description": "مدل جدید GPT-4 Turbo دارای قابلیت‌های بصری است. اکنون، درخواست‌های بصری می‌توانند با استفاده از الگوی JSON و فراخوانی توابع انجام شوند. GPT-4 Turbo یک نسخه بهبود یافته است که پشتیبانی مقرون به صرفه‌ای برای وظایف چندرسانه‌ای ارائه می‌دهد. این مدل تعادل خوبی بین دقت و کارایی برقرار می‌کند و برای برنامه‌هایی که نیاز به تعامل زنده دارند، مناسب است."
  },
  "gpt-4-vision-preview": {
    "description": "مدل جدید GPT-4 Turbo دارای قابلیت‌های بصری است. اکنون، درخواست‌های بصری می‌توانند با استفاده از الگوی JSON و فراخوانی توابع انجام شوند. GPT-4 Turbo یک نسخه بهبود یافته است که پشتیبانی مقرون به صرفه‌ای برای وظایف چندرسانه‌ای ارائه می‌دهد. این مدل تعادل خوبی بین دقت و کارایی برقرار می‌کند و برای برنامه‌هایی که نیاز به تعامل زنده دارند، مناسب است."
  },
  "gpt-4o": {
    "description": "پیشرفته‌ترین مدل چندرسانه‌ای در سری OpenAI GPT-4 که می‌تواند ورودی‌های متنی و تصویری را پردازش کند."
  },
  "gpt-4o-2024-05-13": {
    "description": "ChatGPT-4o یک مدل پویا است که به‌طور زنده به‌روزرسانی می‌شود تا آخرین نسخه را حفظ کند. این مدل ترکیبی از درک و توانایی تولید زبان قوی است و برای سناریوهای کاربردی بزرگ مقیاس، از جمله خدمات مشتری، آموزش و پشتیبانی فنی مناسب است."
  },
  "gpt-4o-2024-08-06": {
    "description": "ChatGPT-4o یک مدل پویا است که به‌طور زنده به‌روزرسانی می‌شود تا آخرین نسخه را حفظ کند. این مدل ترکیبی از درک و توانایی تولید زبان قوی است و برای سناریوهای کاربردی بزرگ مقیاس، از جمله خدمات مشتری، آموزش و پشتیبانی فنی مناسب است."
  },
  "gpt-4o-mini": {
    "description": "یک راه‌حل هوش مصنوعی مقرون به صرفه که برای انواع وظایف متنی و تصویری مناسب است."
  },
  "gryphe/mythomax-l2-13b": {
    "description": "MythoMax l2 13B یک مدل زبان است که خلاقیت و هوش را با هم ترکیب کرده و شامل چندین مدل برتر است."
  },
  "hunyuan-code": {
    "description": "مدل تولید کد جدید مختلط، با استفاده از 200B داده کد با کیفیت بالا برای آموزش مدل پایه، و شش ماه آموزش داده‌های SFT با کیفیت بالا، طول پنجره زمینه به 8K افزایش یافته است و در پنج زبان معیارهای ارزیابی خودکار تولید کد در سطح بالایی قرار دارد؛ در ارزیابی‌های کیفیت بالا در ده معیار مختلف در پنج زبان، عملکرد در رده اول قرار دارد."
  },
  "hunyuan-functioncall": {
    "description": "مدل FunctionCall با ساختار MOE جدید مختلط، پس از آموزش داده‌های FunctionCall با کیفیت بالا، پنجره زمینه به 32K رسیده است و در چندین بعد از معیارهای ارزیابی پیشرو است."
  },
  "hunyuan-lite": {
    "description": "به ساختار MOE ارتقا یافته است، پنجره زمینه 256k دارد و در چندین مجموعه ارزیابی در NLP، کدنویسی، ریاضیات و صنعت از بسیاری از مدل‌های منبع باز پیشی گرفته است."
  },
  "hunyuan-pro": {
    "description": "مدل طولانی با پارامترهای تریلیون MOE-32K. در انواع بنچمارک‌ها به سطح پیشرو دست یافته است و توانایی‌های پیچیده در استنتاج و ریاضیات را داراست و از فراخوانی توابع پشتیبانی می‌کند و در زمینه‌های ترجمه چند زبانه، مالی، حقوقی و پزشکی به‌طور خاص بهینه‌سازی شده است."
  },
  "hunyuan-role": {
    "description": "مدل نقش‌آفرینی جدید مختلط، مدلی است که توسط تیم رسمی مختلط برای آموزش دقیق و بهینه‌سازی شده است و بر اساس مدل مختلط و مجموعه داده‌های سناریوهای نقش‌آفرینی آموزش دیده است و در سناریوهای نقش‌آفرینی عملکرد بهتری دارد."
  },
  "hunyuan-standard": {
    "description": "از استراتژی‌های مسیریابی بهتری استفاده می‌کند و در عین حال مشکلات تعادل بار و همگرایی متخصصان را کاهش می‌دهد. در زمینه متون طولانی، معیار دانه‌برداری به 99.9% رسیده است. MOE-32K از نظر هزینه نسبت به عملکرد بهتری دارد و می‌تواند پردازش ورودی‌های متنی طولانی را به‌خوبی انجام دهد."
  },
  "hunyuan-standard-256K": {
    "description": "از استراتژی‌های مسیریابی بهتری استفاده می‌کند و در عین حال مشکلات تعادل بار و همگرایی متخصصان را کاهش می‌دهد. در زمینه متون طولانی، معیار دانه‌برداری به 99.9% رسیده است. MOE-256K در طول و عملکرد به‌طور قابل توجهی پیشرفت کرده و طول ورودی را به‌طور قابل توجهی گسترش داده است."
  },
  "hunyuan-turbo": {
    "description": "نسخه پیش‌نمایش نسل جدید مدل زبان بزرگ مختلط، با استفاده از ساختار مدل متخصص مختلط (MoE) که نسبت به hunyuan-pro از کارایی استنتاج بهتری برخوردار است و عملکرد بهتری دارد."
  },
  "hunyuan-vision": {
    "description": "مدل چندرسانه‌ای جدید مختلط، از ورودی تصویر و متن برای تولید محتوای متنی پشتیبانی می‌کند."
  },
  "internlm/internlm2_5-20b-chat": {
    "description": "مدل منبع باز نوآورانه InternLM2.5 با افزایش پارامترها، هوش گفتگویی را بهبود می‌بخشد."
  },
  "internlm/internlm2_5-7b-chat": {
    "description": "InternLM2.5 راه‌حل‌های گفتگویی هوشمند را در چندین زمینه ارائه می‌دهد."
  },
  "jamba-1.5-large": {},
  "jamba-1.5-mini": {},
  "llama-3.1-70b-instruct": {
    "description": "مدل Llama 3.1 70B Instruct، با 70B پارامتر، می‌تواند در تولید متن بزرگ و وظایف دستوری عملکرد فوق‌العاده‌ای ارائه دهد."
  },
  "llama-3.1-70b-versatile": {
    "description": "Llama 3.1 70B توانایی استدلال AI قوی‌تری را ارائه می‌دهد و برای کاربردهای پیچیده مناسب است و از پردازش محاسباتی فوق‌العاده‌ای پشتیبانی می‌کند و دقت بالایی را تضمین می‌کند."
  },
  "llama-3.1-8b-instant": {
    "description": "Llama 3.1 8B یک مدل با کارایی بالا است که توانایی تولید متن سریعی را ارائه می‌دهد و برای سناریوهای کاربردی که به کارایی و صرفه‌جویی در هزینه نیاز دارند، بسیار مناسب است."
  },
  "llama-3.1-8b-instruct": {
    "description": "مدل Llama 3.1 8B Instruct، با 8B پارامتر، از اجرای کارآمد وظایف تصویری پشتیبانی می‌کند و قابلیت تولید متن با کیفیت بالا را ارائه می‌دهد."
  },
  "llama-3.1-sonar-huge-128k-online": {
    "description": "مدل Llama 3.1 Sonar Huge Online، با 405B پارامتر، از طول زمینه حدود 127,000 توکن پشتیبانی می‌کند و برای برنامه‌های چت آنلاین پیچیده طراحی شده است."
  },
  "llama-3.1-sonar-large-128k-chat": {
    "description": "مدل Llama 3.1 Sonar Large Chat، با 70B پارامتر، از طول زمینه حدود 127,000 توکن پشتیبانی می‌کند و برای وظایف چت آفلاین پیچیده مناسب است."
  },
  "llama-3.1-sonar-large-128k-online": {
    "description": "مدل Llama 3.1 Sonar Large Online، با 70B پارامتر، از طول زمینه حدود 127,000 توکن پشتیبانی می‌کند و برای وظایف چت با ظرفیت بالا و متنوع مناسب است."
  },
  "llama-3.1-sonar-small-128k-chat": {
    "description": "مدل Llama 3.1 Sonar Small Chat، با 8B پارامتر، به طور خاص برای چت آفلاین طراحی شده و از طول زمینه حدود 127,000 توکن پشتیبانی می‌کند."
  },
  "llama-3.1-sonar-small-128k-online": {
    "description": "مدل Llama 3.1 Sonar Small Online، با 8B پارامتر، از طول زمینه حدود 127,000 توکن پشتیبانی می‌کند و به طور خاص برای چت آنلاین طراحی شده است و می‌تواند به طور کارآمد انواع تعاملات متنی را پردازش کند."
  },
  "llama-3.2-11b-vision-instruct": {
    "description": "توانایی استدلال بصری فوق‌العاده‌ای را در تصاویر با وضوح بالا ارائه می‌دهد و برای کاربردهای درک بصری مناسب است."
  },
  "llama-3.2-11b-vision-preview": {
    "description": "Llama 3.2 برای پردازش وظایفی که شامل داده‌های بصری و متنی است طراحی شده است. این مدل در وظایف توصیف تصویر و پرسش و پاسخ بصری عملکرد فوق‌العاده‌ای دارد و شکاف بین تولید زبان و استدلال بصری را پر می‌کند."
  },
  "llama-3.2-90b-vision-instruct": {
    "description": "توانایی استدلال بصری پیشرفته‌ای برای کاربردهای درک بصری ارائه می‌دهد."
  },
  "llama-3.2-90b-vision-preview": {
    "description": "Llama 3.2 برای پردازش وظایفی که شامل داده‌های بصری و متنی است طراحی شده است. این مدل در وظایف توصیف تصویر و پرسش و پاسخ بصری عملکرد فوق‌العاده‌ای دارد و شکاف بین تولید زبان و استدلال بصری را پر می‌کند."
  },
  "llama3-70b-8192": {
    "description": "مدل Meta Llama 3 70B توانایی پردازش پیچیدگی بی‌نظیری را ارائه می‌دهد و برای پروژه‌های با نیازهای بالا طراحی شده است."
  },
  "llama3-8b-8192": {
    "description": "مدل Meta Llama 3 8B عملکرد استدلال با کیفیتی را ارائه می‌دهد و برای نیازهای کاربردی چندگانه مناسب است."
  },
  "llama3-groq-70b-8192-tool-use-preview": {
    "description": "Llama 3 Groq 70B Tool Use توانایی‌های قوی در فراخوانی ابزارها را ارائه می‌دهد و از پردازش کارآمد وظایف پیچیده پشتیبانی می‌کند."
  },
  "llama3-groq-8b-8192-tool-use-preview": {
    "description": "Llama 3 Groq 8B Tool Use مدلی است که برای استفاده کارآمد از ابزارها بهینه‌سازی شده و از محاسبات موازی سریع پشتیبانی می‌کند."
  },
  "llama3.1": {
    "description": "Llama 3.1 مدل پیشرفته‌ای است که توسط Meta ارائه شده و از حداکثر 405B پارامتر پشتیبانی می‌کند و می‌تواند در زمینه‌های گفتگوی پیچیده، ترجمه چند زبانه و تحلیل داده‌ها استفاده شود."
  },
  "llama3.1:405b": {
    "description": "Llama 3.1 مدل پیشرفته‌ای است که توسط Meta ارائه شده و از حداکثر 405B پارامتر پشتیبانی می‌کند و می‌تواند در زمینه‌های گفتگوی پیچیده، ترجمه چند زبانه و تحلیل داده‌ها استفاده شود."
  },
  "llama3.1:70b": {
    "description": "Llama 3.1 مدل پیشرفته‌ای است که توسط Meta ارائه شده و از حداکثر 405B پارامتر پشتیبانی می‌کند و می‌تواند در زمینه‌های گفتگوی پیچیده، ترجمه چند زبانه و تحلیل داده‌ها استفاده شود."
  },
  "llava": {
    "description": "LLaVA یک مدل چندرسانه‌ای است که ترکیبی از کدگذار بصری و Vicuna است و برای درک قوی بصری و زبانی طراحی شده است."
  },
  "llava-v1.5-7b-4096-preview": {
    "description": "LLaVA 1.5 7B توانایی پردازش بصری را ترکیب می‌کند و از طریق ورودی اطلاعات بصری خروجی‌های پیچیده‌ای تولید می‌کند."
  },
  "llava:13b": {
    "description": "LLaVA یک مدل چندرسانه‌ای است که ترکیبی از کدگذار بصری و Vicuna است و برای درک قوی بصری و زبانی طراحی شده است."
  },
  "llava:34b": {
    "description": "LLaVA یک مدل چندرسانه‌ای است که ترکیبی از کدگذار بصری و Vicuna است و برای درک قوی بصری و زبانی طراحی شده است."
  },
  "mathstral": {
    "description": "MathΣtral به طور خاص برای تحقیقات علمی و استدلال ریاضی طراحی شده و توانایی محاسباتی مؤثر و تفسیر نتایج را ارائه می‌دهد."
  },
  "meta-llama-3-70b-instruct": {
    "description": "مدل 700 میلیارد پارامتری قدرتمند که در استدلال، کدنویسی و کاربردهای زبانی وسیع عملکرد فوق‌العاده‌ای دارد."
  },
  "meta-llama-3-8b-instruct": {
    "description": "مدل 80 میلیارد پارامتری چندمنظوره که برای وظایف گفتگویی و تولید متن بهینه‌سازی شده است."
  },
  "meta-llama-3.1-405b-instruct": {
    "description": "مدل متنی تنظیم‌شده بر اساس دستورالعمل Llama 3.1 که برای موارد گفتگوی چند زبانه بهینه‌سازی شده و در بسیاری از مدل‌های چت متن‌باز و بسته موجود در آزمون‌های مرجع صنعتی رایج عملکرد فوق‌العاده‌ای دارد."
  },
  "meta-llama-3.1-70b-instruct": {
    "description": "مدل متنی تنظیم‌شده بر اساس دستورالعمل Llama 3.1 که برای موارد گفتگوی چند زبانه بهینه‌سازی شده و در بسیاری از مدل‌های چت متن‌باز و بسته موجود در آزمون‌های مرجع صنعتی رایج عملکرد فوق‌العاده‌ای دارد."
  },
  "meta-llama-3.1-8b-instruct": {
    "description": "مدل متنی تنظیم‌شده بر اساس دستورالعمل Llama 3.1 که برای موارد گفتگوی چند زبانه بهینه‌سازی شده و در بسیاری از مدل‌های چت متن‌باز و بسته موجود در آزمون‌های مرجع صنعتی رایج عملکرد فوق‌العاده‌ای دارد."
  },
  "meta-llama/Llama-2-13b-chat-hf": {
    "description": "LLaMA-2 Chat (13B) توانایی‌های پردازش زبان عالی و تجربه تعاملی برجسته‌ای را ارائه می‌دهد."
  },
  "meta-llama/Llama-2-70b-hf": {
    "description": "LLaMA-2 توانایی‌های پردازش زبان عالی و تجربه تعاملی برجسته‌ای را ارائه می‌دهد."
  },
  "meta-llama/Llama-3-70b-chat-hf": {
    "description": "مدل Llama 3 70B Instruct Reference یک مدل گفتگویی قدرتمند است که از نیازهای گفتگوی پیچیده پشتیبانی می‌کند."
  },
  "meta-llama/Llama-3-8b-chat-hf": {
    "description": "مدل Llama 3 8B Instruct Reference از چند زبان پشتیبانی می‌کند و شامل دانش گسترده‌ای از حوزه‌های مختلف است."
  },
  "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo": {
    "description": "LLaMA 3.2 برای پردازش وظایفی که شامل داده‌های بصری و متنی است طراحی شده است. این مدل در وظایف توصیف تصویر و پرسش و پاسخ بصری عملکرد خوبی دارد و شکاف بین تولید زبان و استدلال بصری را پر می‌کند."
  },
  "meta-llama/Llama-3.2-3B-Instruct-Turbo": {
    "description": "LLaMA 3.2 برای پردازش وظایفی که شامل داده‌های بصری و متنی است طراحی شده است. این مدل در وظایف توصیف تصویر و پرسش و پاسخ بصری عملکرد خوبی دارد و شکاف بین تولید زبان و استدلال بصری را پر می‌کند."
  },
  "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo": {
    "description": "LLaMA 3.2 برای پردازش وظایفی که شامل داده‌های بصری و متنی است طراحی شده است. این مدل در وظایف توصیف تصویر و پرسش و پاسخ بصری عملکرد خوبی دارد و شکاف بین تولید زبان و استدلال بصری را پر می‌کند."
  },
  "meta-llama/Llama-Vision-Free": {
    "description": "LLaMA 3.2 برای پردازش وظایفی که شامل داده‌های بصری و متنی است طراحی شده است. این مدل در وظایف توصیف تصویر و پرسش و پاسخ بصری عملکرد خوبی دارد و شکاف بین تولید زبان و استدلال بصری را پر می‌کند."
  },
  "meta-llama/Meta-Llama-3-70B-Instruct-Lite": {
    "description": "مدل Llama 3 70B Instruct Lite برای محیط‌هایی که به کارایی بالا و تأخیر کم نیاز دارند مناسب است."
  },
  "meta-llama/Meta-Llama-3-70B-Instruct-Turbo": {
    "description": "مدل Llama 3 70B Instruct Turbo توانایی‌های درک و تولید زبان برجسته‌ای را ارائه می‌دهد و برای سخت‌ترین وظایف محاسباتی مناسب است."
  },
  "meta-llama/Meta-Llama-3-8B-Instruct-Lite": {
    "description": "مدل Llama 3 8B Instruct Lite برای محیط‌های با منابع محدود مناسب است و تعادل عملکرد عالی را ارائه می‌دهد."
  },
  "meta-llama/Meta-Llama-3-8B-Instruct-Turbo": {
    "description": "مدل Llama 3 8B Instruct Turbo یک مدل زبانی با کارایی بالا است که از سناریوهای کاربردی گسترده پشتیبانی می‌کند."
  },
  "meta-llama/Meta-Llama-3.1-405B-Instruct": {
    "description": "مدل میکرو تنظیم شده LLaMA 3.1 405B برای سناریوهای گفتگوی چند زبانه بهینه‌سازی شده است."
  },
  "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo": {
    "description": "مدل Llama 3.1 Turbo 405B برای پردازش داده‌های بزرگ، پشتیبانی از ظرفیت بالای زمینه را ارائه می‌دهد و در کاربردهای هوش مصنوعی با مقیاس بسیار بزرگ عملکرد برجسته‌ای دارد."
  },
  "meta-llama/Meta-Llama-3.1-70B-Instruct": {
    "description": "LLaMA 3.1 70B پشتیبانی کارآمدی از گفتگوی چند زبانه ارائه می‌دهد."
  },
  "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": {
    "description": "مدل Llama 3.1 70B به‌طور دقیق تنظیم شده و برای کاربردهای با بار بالا مناسب است، با کم‌فشاری به FP8، توان محاسباتی و دقت بالاتری را ارائه می‌دهد و در سناریوهای پیچیده عملکرد برجسته‌ای دارد."
  },
  "meta-llama/Meta-Llama-3.1-8B-Instruct": {
    "description": "LLaMA 3.1 از چندین زبان پشتیبانی می‌کند و یکی از مدل‌های تولیدی پیشرو در صنعت است."
  },
  "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": {
    "description": "مدل Llama 3.1 8B با FP8 کم‌فشاری، از 131,072 نشانه زمینه پشتیبانی می‌کند و یکی از بهترین مدل‌های متن باز است که برای وظایف پیچیده مناسب است و در بسیاری از معیارهای صنعتی عملکرد بهتری دارد."
  },
  "meta-llama/llama-3-70b-instruct": {
    "description": "مدل Llama 3 70B Instruct برای بهینه‌سازی سناریوهای مکالمه با کیفیت بالا طراحی شده و در ارزیابی‌های انسانی عملکرد فوق‌العاده‌ای دارد."
  },
  "meta-llama/llama-3-8b-instruct": {
    "description": "مدل Llama 3 8B Instruct برای بهینه‌سازی سناریوهای مکالمه با کیفیت بالا طراحی شده و عملکردی بهتر از بسیاری از مدل‌های بسته دارد."
  },
  "meta-llama/llama-3.1-405b-instruct": {
    "description": "مدل Llama 3.1 405B Instruct جدیدترین نسخه متا است که برای تولید مکالمات با کیفیت بالا بهینه‌سازی شده و از بسیاری از مدل‌های بسته پیشرو فراتر رفته است."
  },
  "meta-llama/llama-3.1-70b-instruct": {
    "description": "مدل Llama 3.1 70B Instruct به طور خاص برای مکالمات با کیفیت بالا طراحی شده و در ارزیابی‌های انسانی عملکرد برجسته‌ای دارد، به ویژه برای سناریوهای با تعامل بالا."
  },
  "meta-llama/llama-3.1-8b-instruct": {
    "description": "مدل Llama 3.1 8B Instruct جدیدترین نسخه متا است که برای بهینه‌سازی سناریوهای مکالمه با کیفیت بالا طراحی شده و عملکردی بهتر از بسیاری از مدل‌های بسته پیشرو دارد."
  },
  "meta-llama/llama-3.1-8b-instruct:free": {
    "description": "LLaMA 3.1 از چند زبان پشتیبانی می‌کند و یکی از مدل‌های تولیدی پیشرو در صنعت است."
  },
  "meta-llama/llama-3.2-11b-vision-instruct": {
    "description": "LLaMA 3.2 برای پردازش وظایفی که شامل داده‌های بصری و متنی است طراحی شده است. این مدل در وظایف توصیف تصویر و پرسش و پاسخ بصری عملکرد خوبی دارد و شکاف بین تولید زبان و استدلال بصری را پر می‌کند."
  },
  "meta-llama/llama-3.2-90b-vision-instruct": {
    "description": "LLaMA 3.2 برای پردازش وظایفی که شامل داده‌های بصری و متنی است طراحی شده است. این مدل در وظایف توصیف تصویر و پرسش و پاسخ بصری عملکرد خوبی دارد و شکاف بین تولید زبان و استدلال بصری را پر می‌کند."
  },
  "meta.llama3-1-405b-instruct-v1:0": {
    "description": "مدل Meta Llama 3.1 405B Instruct بزرگترین و قدرتمندترین مدل در مجموعه مدل‌های Llama 3.1 Instruct است. این مدل یک مدل پیشرفته برای استدلال گفتگویی و تولید داده‌های ترکیبی است و می‌تواند به عنوان پایه‌ای برای پیش‌آموزش یا تنظیم دقیق در زمینه‌های خاص استفاده شود. مدل‌های زبان بزرگ چند زبانه (LLMs) ارائه شده توسط Llama 3.1 شامل مدل‌های تولیدی پیش‌آموزش‌دیده و تنظیم‌شده بر اساس دستورالعمل هستند که شامل اندازه‌های 8B، 70B و 405B (ورودی/خروجی متنی) می‌باشند. مدل‌های متنی تنظیم‌شده بر اساس دستورالعمل Llama 3.1 (8B، 70B، 405B) به طور خاص برای موارد گفتگوی چند زبانه بهینه‌سازی شده‌اند و در بسیاری از آزمون‌های مرجع صنعتی رایج از بسیاری از مدل‌های چت متن‌باز موجود پیشی گرفته‌اند. Llama 3.1 برای استفاده‌های تجاری و تحقیقاتی در چندین زبان طراحی شده است. مدل‌های متنی تنظیم‌شده بر اساس دستورالعمل برای چت‌های مشابه دستیار مناسب هستند، در حالی که مدل‌های پیش‌آموزش‌دیده می‌توانند به انواع وظایف تولید زبان طبیعی سازگار شوند. مدل‌های Llama 3.1 همچنین از خروجی مدل خود برای بهبود سایر مدل‌ها، از جمله تولید داده‌های ترکیبی و تصفیه استفاده می‌کنند. Llama 3.1 یک مدل زبان خودبازگشتی است که با استفاده از معماری بهینه‌سازی شده ترنسفورمر ساخته شده است. نسخه تنظیم‌شده از یادگیری نظارتی (SFT) و یادگیری تقویتی با بازخورد انسانی (RLHF) برای مطابقت با ترجیحات انسانی در مورد کمک و ایمنی استفاده می‌کند."
  },
  "meta.llama3-1-70b-instruct-v1:0": {
    "description": "نسخه به‌روزرسانی شده Meta Llama 3.1 70B Instruct که شامل طول زمینه 128K، چندزبانی و بهبود در توانایی استدلال است. مدل‌های زبان بزرگ چندزبانی (LLMs) ارائه شده توسط Llama 3.1 شامل مجموعه‌ای از مدل‌های تولیدی پیش‌آموزش شده و تنظیم شده با دستورالعمل هستند که شامل اندازه‌های 8B، 70B و 405B (ورودی/خروجی متنی) می‌باشند. مدل‌های متنی تنظیم شده با دستورالعمل Llama 3.1 (8B، 70B، 405B) به طور خاص برای موارد استفاده مکالمه‌ای چندزبانه بهینه‌سازی شده‌اند و در آزمون‌های مرجع صنعتی رایج از بسیاری از مدل‌های چت متن باز موجود پیشی گرفته‌اند. Llama 3.1 برای استفاده‌های تجاری و تحقیقاتی در زبان‌های مختلف طراحی شده است. مدل‌های متنی تنظیم شده با دستورالعمل برای چت‌های مشابه دستیار مناسب هستند، در حالی که مدل‌های پیش‌آموزش شده می‌توانند برای انواع وظایف تولید زبان طبیعی سازگار شوند. مدل‌های Llama 3.1 همچنین از خروجی مدل خود برای بهبود سایر مدل‌ها، از جمله تولید داده‌های ترکیبی و تصفیه استفاده می‌کنند. Llama 3.1 یک مدل زبان خودبازگشتی است که با استفاده از معماری بهینه‌سازی شده ترنسفورمر ساخته شده است. نسخه‌های تنظیم شده از یادگیری نظارتی (SFT) و یادگیری تقویتی با بازخورد انسانی (RLHF) برای مطابقت با ترجیحات انسانی در کمک و ایمنی استفاده می‌کنند."
  },
  "meta.llama3-1-8b-instruct-v1:0": {
    "description": "نسخه به‌روزرسانی شده Meta Llama 3.1 8B Instruct که شامل طول زمینه 128K، چندزبانی و بهبود در توانایی استدلال است. مدل‌های زبان بزرگ چندزبانی (LLMs) ارائه شده توسط Llama 3.1 شامل مجموعه‌ای از مدل‌های تولیدی پیش‌آموزش شده و تنظیم شده با دستورالعمل هستند که شامل اندازه‌های 8B، 70B و 405B (ورودی/خروجی متنی) می‌باشند. مدل‌های متنی تنظیم شده با دستورالعمل Llama 3.1 (8B، 70B، 405B) به طور خاص برای موارد استفاده مکالمه‌ای چندزبانه بهینه‌سازی شده‌اند و در آزمون‌های مرجع صنعتی رایج از بسیاری از مدل‌های چت متن باز موجود پیشی گرفته‌اند. Llama 3.1 برای استفاده‌های تجاری و تحقیقاتی در زبان‌های مختلف طراحی شده است. مدل‌های متنی تنظیم شده با دستورالعمل برای چت‌های مشابه دستیار مناسب هستند، در حالی که مدل‌های پیش‌آموزش شده می‌توانند برای انواع وظایف تولید زبان طبیعی سازگار شوند. مدل‌های Llama 3.1 همچنین از خروجی مدل خود برای بهبود سایر مدل‌ها، از جمله تولید داده‌های ترکیبی و تصفیه استفاده می‌کنند. Llama 3.1 یک مدل زبان خودبازگشتی است که با استفاده از معماری بهینه‌سازی شده ترنسفورمر ساخته شده است. نسخه‌های تنظیم شده از یادگیری نظارتی (SFT) و یادگیری تقویتی با بازخورد انسانی (RLHF) برای مطابقت با ترجیحات انسانی در کمک و ایمنی استفاده می‌کنند."
  },
  "meta.llama3-70b-instruct-v1:0": {
    "description": "مدل Meta Llama 3 یک مدل زبان بزرگ (LLM) باز برای توسعه‌دهندگان، محققان و شرکت‌ها است که به آنها کمک می‌کند ایده‌های تولید AI خود را بسازند، آزمایش کنند و به طور مسئولانه گسترش دهند. به عنوان بخشی از سیستم‌های پایه نوآوری جامعه جهانی، این مدل برای ایجاد محتوا، AI گفتگویی، درک زبان، تحقیق و توسعه و کاربردهای شرکتی بسیار مناسب است."
  },
  "meta.llama3-8b-instruct-v1:0": {
    "description": "مدل Meta Llama 3 یک مدل زبان بزرگ (LLM) باز برای توسعه‌دهندگان، محققان و شرکت‌ها است که به آنها کمک می‌کند ایده‌های تولید AI خود را بسازند، آزمایش کنند و به طور مسئولانه گسترش دهند. به عنوان بخشی از سیستم‌های پایه نوآوری جامعه جهانی، این مدل برای دستگاه‌های با توان محاسباتی و منابع محدود، دستگاه‌های لبه و زمان‌های آموزش سریع‌تر بسیار مناسب است."
  },
  "microsoft/wizardlm 2-7b": {
    "description": "WizardLM 2 7B جدیدترین مدل سریع و سبک مایکروسافت است که عملکردی نزدیک به 10 برابر مدل‌های پیشرو منبع باز موجود دارد."
  },
  "microsoft/wizardlm-2-8x22b": {
    "description": "WizardLM-2 8x22B پیشرفته‌ترین مدل Wizard مایکروسافت است که عملکردی بسیار رقابتی را نشان می‌دهد."
  },
  "minicpm-v": {
    "description": "MiniCPM-V یک مدل بزرگ چندرسانه‌ای نسل جدید است که توسط OpenBMB ارائه شده و دارای قابلیت‌های عالی OCR و درک چندرسانه‌ای است و از سناریوهای کاربردی گسترده پشتیبانی می‌کند."
  },
  "ministral-3b-latest": {
    "description": "Ministral 3B مدل برتر Mistral در سطح جهانی است."
  },
  "ministral-8b-latest": {
    "description": "Ministral 8B مدل با هزینه به صرفه Mistral است."
  },
  "mistral": {
    "description": "Mistral یک مدل 7B است که توسط Mistral AI منتشر شده و برای نیازهای پردازش زبان متغیر مناسب است."
  },
  "mistral-large": {
    "description": "Mixtral Large مدل پرچمدار Mistral است که توانایی‌های تولید کد، ریاضی و استدلال را ترکیب می‌کند و از پنجره زمینه 128k پشتیبانی می‌کند."
  },
  "mistral-large-latest": {
    "description": "Mistral Large مدل پرچمدار است که در وظایف چند زبانه، استدلال پیچیده و تولید کد تخصص دارد و انتخاب ایده‌آلی برای کاربردهای پیشرفته است."
  },
  "mistral-nemo": {
    "description": "Mistral Nemo که توسط Mistral AI و NVIDIA همکاری شده است، یک مدل 12B با عملکرد کارآمد است."
  },
  "mistral-small": {
    "description": "Mistral Small برای هر وظیفه مبتنی بر زبان که به کارایی بالا و تأخیر کم نیاز دارد، مناسب است."
  },
  "mistral-small-latest": {
    "description": "Mistral Small گزینه‌ای با هزینه به صرفه، سریع و قابل اعتماد است که برای مواردی مانند ترجمه، خلاصه‌سازی و تحلیل احساسات مناسب است."
  },
  "mistralai/Mistral-7B-Instruct-v0.1": {
    "description": "Mistral (7B) Instruct به خاطر عملکرد بالا شناخته شده و برای وظایف زبانی مختلف مناسب است."
  },
  "mistralai/Mistral-7B-Instruct-v0.2": {
    "description": "مدل بهینه‌سازی شده Mistral AI برای دستورات"
  },
  "mistralai/Mistral-7B-Instruct-v0.3": {
    "description": "Mistral (7B) Instruct v0.3 توانایی‌های محاسباتی کارآمد و درک زبان طبیعی را ارائه می‌دهد و برای کاربردهای گسترده مناسب است."
  },
  "mistralai/Mistral-7B-v0.1": {
    "description": "Mistral 7B یک مدل فشرده اما با عملکرد بالا است که در پردازش دسته‌ای و وظایف ساده مانند طبقه‌بندی و تولید متن مهارت دارد و دارای توانایی استدلال خوبی است."
  },
  "mistralai/Mixtral-8x22B-Instruct-v0.1": {
    "description": "Mixtral-8x22B Instruct (141B) یک مدل زبان بزرگ فوق‌العاده است که از نیازهای پردازش بسیار بالا پشتیبانی می‌کند."
  },
  "mistralai/Mixtral-8x7B-Instruct-v0.1": {
    "description": "Mixtral-8x7B Instruct (46.7B) یک چارچوب محاسباتی با ظرفیت بالا ارائه می‌دهد و برای پردازش داده‌های بزرگ مقیاس مناسب است."
  },
  "mistralai/Mixtral-8x7B-v0.1": {
    "description": "Mixtral 8x7B یک مدل متخصص نازک است که با استفاده از چندین پارامتر سرعت استدلال را افزایش می‌دهد و برای پردازش چند زبانه و تولید کد مناسب است."
  },
  "mistralai/mistral-7b-instruct": {
    "description": "مدل Mistral 7B Instruct یک مدل استاندارد صنعتی با بهینه‌سازی سرعت و پشتیبانی از زمینه طولانی است."
  },
  "mistralai/mistral-nemo": {
    "description": "Mistral Nemo یک مدل با 7.3B پارامتر است که از پشتیبانی چند زبانه و برنامه‌نویسی با عملکرد بالا برخوردار است."
  },
  "mixtral": {
    "description": "Mixtral یک مدل تخصصی از Mistral AI است که دارای وزن‌های متن باز بوده و در تولید کد و درک زبان پشتیبانی می‌کند."
  },
  "mixtral-8x7b-32768": {
    "description": "Mixtral 8x7B توانایی محاسبات موازی با تحمل خطای بالا را ارائه می‌دهد و برای وظایف پیچیده مناسب است."
  },
  "mixtral:8x22b": {
    "description": "Mixtral یک مدل تخصصی از Mistral AI است که دارای وزن‌های متن باز بوده و در تولید کد و درک زبان پشتیبانی می‌کند."
  },
  "moonshot-v1-128k": {
    "description": "Moonshot V1 128K مدلی است که دارای توانایی پردازش زمینه‌های فوق‌العاده طولانی است و برای تولید متن‌های فوق‌العاده طولانی مناسب است و نیازهای پیچیده تولید را برآورده می‌کند و می‌تواند محتوای حداکثر 128,000 توکن را پردازش کند و برای کاربردهای تحقیقاتی، دانشگاهی و تولید اسناد بزرگ بسیار مناسب است."
  },
  "moonshot-v1-32k": {
    "description": "Moonshot V1 32K توانایی پردازش زمینه‌های با طول متوسط را ارائه می‌دهد و می‌تواند 32,768 توکن را پردازش کند و به ویژه برای تولید انواع اسناد طولانی و گفتگوی پیچیده مناسب است و در زمینه‌های تولید محتوا، تولید گزارش و سیستم‌های گفتگویی کاربرد دارد."
  },
  "moonshot-v1-8k": {
    "description": "Moonshot V1 8K به طور خاص برای تولید وظایف متن کوتاه طراحی شده است و دارای عملکرد پردازش کارآمدی است که می‌تواند 8,192 توکن را پردازش کند و برای گفتگوی کوتاه، یادداشت‌برداری و تولید محتوای سریع بسیار مناسب است."
  },
  "nousresearch/hermes-2-pro-llama-3-8b": {
    "description": "Hermes 2 Pro Llama 3 8B نسخه به‌روزرسانی شده Nous Hermes 2 است که شامل جدیدترین مجموعه داده‌های توسعه داخلی است."
  },
  "nvidia/Llama-3.1-Nemotron-70B-Instruct": {
    "description": "Llama 3.1 Nemotron 70B یک مدل زبان بزرگ سفارشی شده توسط NVIDIA است که به منظور افزایش کمک به پاسخ‌های تولید شده توسط LLM به پرسش‌های کاربران طراحی شده است."
  },
  "o1-mini": {
    "description": "کوچک‌تر و سریع‌تر از o1-preview، با هزینه‌ای 80% کمتر و عملکرد خوب در تولید کد و عملیات کوچک."
  },
  "o1-preview": {
    "description": "متمرکز بر استدلال پیشرفته و حل مسائل پیچیده، از جمله وظایف ریاضی و علمی. بسیار مناسب برای برنامه‌هایی که نیاز به درک عمیق از زمینه و جریان کار خودکار دارند."
  },
  "open-codestral-mamba": {
    "description": "Codestral Mamba یک مدل زبان Mamba 2 است که بر روی تولید کد تمرکز دارد و از وظایف پیشرفته کد و استدلال به شدت پشتیبانی می‌کند."
  },
  "open-mistral-7b": {
    "description": "Mistral 7B مدلی فشرده اما با عملکرد بالا است که در پردازش دسته‌ای و وظایف ساده مانند طبقه‌بندی و تولید متن تخصص دارد و دارای توانایی استدلال خوبی است."
  },
  "open-mistral-nemo": {
    "description": "Mistral Nemo یک مدل 12B است که به طور مشترک با Nvidia توسعه یافته و عملکرد استدلال و کدنویسی فوق‌العاده‌ای را ارائه می‌دهد و به راحتی قابل ادغام و جایگزینی است."
  },
  "open-mixtral-8x22b": {
    "description": "Mixtral 8x22B یک مدل متخصص بزرگتر است که بر روی وظایف پیچیده تمرکز دارد و توانایی استدلال فوق‌العاده و نرخ پردازش بالاتری را ارائه می‌دهد."
  },
  "open-mixtral-8x7b": {
    "description": "Mixtral 8x7B یک مدل متخصص پراکنده است که با استفاده از چندین پارامتر سرعت استدلال را افزایش می‌دهد و برای پردازش وظایف چند زبانه و تولید کد مناسب است."
  },
  "openai/gpt-4o": {
    "description": "ChatGPT-4o یک مدل پویا است که به‌طور زنده به‌روزرسانی می‌شود تا آخرین نسخه را حفظ کند. این مدل ترکیبی از توانایی‌های قوی در درک و تولید زبان است و برای سناریوهای کاربردی بزرگ مقیاس، از جمله خدمات مشتری، آموزش و پشتیبانی فنی مناسب است."
  },
  "openai/gpt-4o-mini": {
    "description": "GPT-4o mini جدیدترین مدل OpenAI است که پس از GPT-4 Omni ارائه شده و از ورودی‌های متنی و تصویری پشتیبانی می‌کند. به عنوان کوچک‌ترین مدل پیشرفته آن‌ها، این مدل نسبت به سایر مدل‌های پیشرفته اخیر بسیار ارزان‌تر است و بیش از 60% ارزان‌تر از GPT-3.5 Turbo است. این مدل هوش پیشرفته‌ای را حفظ کرده و دارای نسبت قیمت به عملکرد قابل توجهی است. GPT-4o mini در آزمون MMLU نمره 82% را کسب کرده و در ترجیحات چت بالاتر از GPT-4 قرار دارد."
  },
  "openai/o1-mini": {
    "description": "o1-mini یک مدل استدلال سریع و اقتصادی است که برای سناریوهای برنامه‌نویسی، ریاضی و علمی طراحی شده است. این مدل دارای 128K زمینه و تاریخ قطع دانش در اکتبر 2023 است."
  },
  "openai/o1-preview": {
    "description": "o1 مدل جدید استدلال OpenAI است که برای وظایف پیچیده‌ای که به دانش عمومی گسترده نیاز دارند مناسب است. این مدل دارای 128K زمینه و تاریخ قطع دانش در اکتبر 2023 است."
  },
  "openchat/openchat-7b": {
    "description": "OpenChat 7B یک مدل زبان منبع باز است که با استراتژی «C-RLFT (تقویت یادگیری شرطی)» به دقت تنظیم شده است."
  },
  "openrouter/auto": {
    "description": "بر اساس طول زمینه، موضوع و پیچیدگی، درخواست شما به Llama 3 70B Instruct، Claude 3.5 Sonnet (تنظیم خودکار) یا GPT-4o ارسال خواهد شد."
  },
  "phi3": {
    "description": "Phi-3 یک مدل باز سبک است که توسط مایکروسافت ارائه شده و برای ادغام کارآمد و استدلال دانش در مقیاس بزرگ مناسب است."
  },
  "phi3:14b": {
    "description": "Phi-3 یک مدل باز سبک است که توسط مایکروسافت ارائه شده و برای ادغام کارآمد و استدلال دانش در مقیاس بزرگ مناسب است."
  },
  "pixtral-12b-2409": {
    "description": "مدل Pixtral در وظایف درک نمودار و تصویر، پرسش و پاسخ مستند، استدلال چندرسانه‌ای و پیروی از دستورالعمل‌ها عملکرد قوی دارد و می‌تواند تصاویر را با وضوح طبیعی و نسبت ابعاد ورودی کند و همچنین می‌تواند در پنجره زمینه طولانی تا 128K توکن، هر تعداد تصویر را پردازش کند."
  },
  "qwen-coder-turbo-latest": {
    "description": "مدل کد Tongyi Qwen."
  },
  "qwen-long": {
    "description": "مدل زبان بزرگ مقیاس Tongyi Qwen، از زمینه‌های متنی طولانی و قابلیت‌های گفت‌وگو در سناریوهای مبتنی بر اسناد طولانی و چند سندی پشتیبانی می‌کند."
  },
  "qwen-math-plus-latest": {
    "description": "مدل ریاضی Tongyi Qwen که به طور خاص برای حل مسائل ریاضی طراحی شده است."
  },
  "qwen-math-turbo-latest": {
    "description": "مدل ریاضی Tongyi Qwen که به طور خاص برای حل مسائل ریاضی طراحی شده است."
  },
  "qwen-max-latest": {
    "description": "مدل زبان بزرگ مقیاس Tongyi Qwen با مقیاس میلیاردی، از ورودی‌های مختلف زبانی مانند چینی و انگلیسی پشتیبانی می‌کند و در حال حاضر مدل API پشت نسخه 2.5 Tongyi Qwen است."
  },
  "qwen-plus-latest": {
    "description": "نسخه تقویت شده مدل زبان بزرگ مقیاس Tongyi Qwen، از ورودی‌های مختلف زبانی مانند چینی و انگلیسی پشتیبانی می‌کند."
  },
  "qwen-turbo-latest": {
    "description": "مدل زبان بزرگ مقیاس Tongyi Qwen، از ورودی‌های مختلف زبانی مانند چینی و انگلیسی پشتیبانی می‌کند."
  },
  "qwen-vl-chat-v1": {
    "description": "مدل Tongyi Qwen VL که از روش‌های تعامل انعطاف‌پذیر، از جمله چند تصویر، پرسش و پاسخ چند دور و خلاقیت پشتیبانی می‌کند."
  },
  "qwen-vl-max-latest": {
    "description": "مدل زبان بصری بزرگ مقیاس Tongyi Qwen. نسبت به نسخه تقویت شده، توانایی استدلال بصری و پیروی از دستورات را بهبود می‌بخشد و سطح بالاتری از درک و ادراک بصری را ارائه می‌دهد."
  },
  "qwen-vl-plus-latest": {
    "description": "نسخه تقویت شده مدل زبان بصری Tongyi Qwen. به طور قابل توجهی توانایی شناسایی جزئیات و شناسایی متن را افزایش می‌دهد و از وضوح تصویر بیش از یک میلیون پیکسل و نسبت ابعاد دلخواه پشتیبانی می‌کند."
  },
  "qwen-vl-v1": {
    "description": "مدل پیش‌آموزش شده با ورودی تصویر با وضوح 448 که با مدل زبان Qwen-7B آغاز شده است."
  },
  "qwen/qwen-2-7b-instruct:free": {
    "description": "Qwen2 یک سری جدید از مدل‌های زبانی بزرگ است که دارای توانایی‌های درک و تولید قوی‌تری است."
  },
  "qwen2": {
    "description": "Qwen2 نسل جدید مدل‌های زبانی بزرگ Alibaba است که با عملکرد عالی از نیازهای کاربردی متنوع پشتیبانی می‌کند."
  },
  "qwen2.5-14b-instruct": {
    "description": "مدل 14B مقیاس Tongyi Qwen 2.5 که به صورت متن باز ارائه شده است."
  },
  "qwen2.5-32b-instruct": {
    "description": "مدل 32B مقیاس Tongyi Qwen 2.5 که به صورت متن باز ارائه شده است."
  },
  "qwen2.5-72b-instruct": {
    "description": "مدل 72B مقیاس Tongyi Qwen 2.5 که به صورت متن باز ارائه شده است."
  },
  "qwen2.5-7b-instruct": {
    "description": "مدل 7B مقیاس Tongyi Qwen 2.5 که به صورت متن باز ارائه شده است."
  },
  "qwen2.5-coder-1.5b-instruct": {
    "description": "نسخه متن باز مدل کد Tongyi Qwen."
  },
  "qwen2.5-coder-7b-instruct": {
    "description": "نسخه متن باز مدل کد Tongyi Qwen."
  },
  "qwen2.5-math-1.5b-instruct": {
    "description": "مدل Qwen-Math دارای توانایی‌های قوی در حل مسائل ریاضی."
  },
  "qwen2.5-math-72b-instruct": {
    "description": "مدل Qwen-Math دارای توانایی‌های قوی در حل مسائل ریاضی."
  },
  "qwen2.5-math-7b-instruct": {
    "description": "مدل Qwen-Math دارای توانایی‌های قوی در حل مسائل ریاضی."
  },
  "qwen2:0.5b": {
    "description": "Qwen2 نسل جدید مدل‌های زبانی بزرگ Alibaba است که با عملکرد عالی از نیازهای کاربردی متنوع پشتیبانی می‌کند."
  },
  "qwen2:1.5b": {
    "description": "Qwen2 نسل جدید مدل‌های زبانی بزرگ Alibaba است که با عملکرد عالی از نیازهای کاربردی متنوع پشتیبانی می‌کند."
  },
  "qwen2:72b": {
    "description": "Qwen2 نسل جدید مدل‌های زبانی بزرگ Alibaba است که با عملکرد عالی از نیازهای کاربردی متنوع پشتیبانی می‌کند."
  },
  "solar-1-mini-chat": {
    "description": "Solar Mini یک LLM جمع و جور است که عملکرد بهتری نسبت به GPT-3.5 دارد و دارای توانایی‌های چند زبانه قوی است و از زبان‌های انگلیسی و کره‌ای پشتیبانی می‌کند و راه‌حل‌های کارآمد و کوچکی را ارائه می‌دهد."
  },
  "solar-1-mini-chat-ja": {
    "description": "Solar Mini (Ja) توانایی‌های Solar Mini را گسترش می‌دهد و بر زبان ژاپنی تمرکز دارد و در استفاده از زبان‌های انگلیسی و کره‌ای نیز کارایی و عملکرد برجسته‌ای را حفظ می‌کند."
  },
  "solar-pro": {
    "description": "Solar Pro یک LLM با هوش بالا است که توسط Upstage معرفی شده و بر توانایی پیروی از دستورات در یک GPU متمرکز است و نمره IFEval بالای 80 را کسب کرده است. در حال حاضر از زبان انگلیسی پشتیبانی می‌کند و نسخه رسمی آن در نوامبر 2024 منتشر خواهد شد و پشتیبانی از زبان‌ها و طول متن را گسترش خواهد داد."
  },
  "step-1-128k": {
    "description": "تعادل بین عملکرد و هزینه، مناسب برای سناریوهای عمومی."
  },
  "step-1-256k": {
    "description": "توانایی پردازش زمینه فوق‌العاده طولانی، به ویژه برای تحلیل مستندات طولانی."
  },
  "step-1-32k": {
    "description": "پشتیبانی از مکالمات با طول متوسط، مناسب برای انواع سناریوها."
  },
  "step-1-8k": {
    "description": "مدل کوچک، مناسب برای وظایف سبک."
  },
  "step-1-flash": {
    "description": "مدل سریع، مناسب برای مکالمات زنده."
  },
  "step-1.5v-turbo": {
    "description": "این مدل دارای توانایی‌های قوی در درک ویدیو است."
  },
  "step-1v-32k": {
    "description": "پشتیبانی از ورودی بصری، تجربه تعامل چندرسانه‌ای را تقویت می‌کند."
  },
  "step-1v-8k": {
    "description": "مدل بصری کوچک، مناسب برای وظایف پایه تصویر و متن."
  },
  "step-2-16k": {
    "description": "پشتیبانی از تعاملات زمینه بزرگ، مناسب برای سناریوهای مکالمه پیچیده."
  },
  "taichu_llm": {
    "description": "Taichu 2.0 بر اساس داده‌های با کیفیت بالا و فراوان آموزش دیده و دارای توانایی‌های قوی در درک متن، تولید محتوا و پرسش و پاسخ است."
  },
  "togethercomputer/StripedHyena-Nous-7B": {
    "description": "StripedHyena Nous (7B) با استفاده از استراتژی‌ها و معماری مدل کارآمد، توانایی محاسباتی بهبود یافته‌ای را ارائه می‌دهد."
  },
  "upstage/SOLAR-10.7B-Instruct-v1.0": {
    "description": "Upstage SOLAR Instruct v1 (11B) برای وظایف دستوری دقیق طراحی شده و توانایی‌های پردازش زبان عالی را ارائه می‌دهد."
  },
  "wizardlm2": {
    "description": "WizardLM 2 یک مدل زبانی است که توسط AI مایکروسافت ارائه شده و در زمینه‌های گفتگوی پیچیده، چند زبانه، استدلال و دستیار هوشمند به ویژه عملکرد خوبی دارد."
  },
  "wizardlm2:8x22b": {
    "description": "WizardLM 2 یک مدل زبانی است که توسط AI مایکروسافت ارائه شده و در زمینه‌های گفتگوی پیچیده، چند زبانه، استدلال و دستیار هوشمند به ویژه عملکرد خوبی دارد."
  },
  "yi-large": {
    "description": "مدل جدید با پارامترهای هزار میلیاردی، توانایی‌های فوق‌العاده در پرسش و پاسخ و تولید متن را ارائه می‌دهد."
  },
  "yi-large-fc": {
    "description": "بر اساس مدل yi-large، توانایی فراخوانی ابزار را پشتیبانی و تقویت کرده و برای انواع سناریوهای تجاری که نیاز به ساخت agent یا workflow دارند، مناسب است."
  },
  "yi-large-preview": {
    "description": "نسخه اولیه، توصیه می‌شود از yi-large (نسخه جدید) استفاده کنید."
  },
  "yi-large-rag": {
    "description": "خدمات پیشرفته مبتنی بر مدل فوق‌العاده yi-large، با ترکیب تکنیک‌های جستجو و تولید برای ارائه پاسخ‌های دقیق و خدمات جستجوی اطلاعات در زمان واقعی."
  },
  "yi-large-turbo": {
    "description": "عملکرد فوق‌العاده با قیمت مناسب. بهینه‌سازی دقیق با توجه به عملکرد، سرعت استنتاج و هزینه."
  },
  "yi-lightning": {
    "description": "مدل جدید با عملکرد بالا، تضمین‌کننده خروجی با کیفیت بالا و در عین حال افزایش سرعت استنتاج."
  },
  "yi-lightning-lite": {
    "description": "نسخه سبک، توصیه می‌شود از yi-lightning استفاده کنید."
  },
  "yi-medium": {
    "description": "مدل با اندازه متوسط که به‌روزرسانی و تنظیم دقیق شده و توانایی‌های متوازن و قیمت مناسبی دارد. توانایی پیروی از دستورات به طور عمیق بهینه‌سازی شده است."
  },
  "yi-medium-200k": {
    "description": "پنجره زمینه فوق‌العاده طولانی 200K، توانایی درک و تولید عمیق متن‌های طولانی را ارائه می‌دهد."
  },
  "yi-spark": {
    "description": "مدل کوچک و سریع، با توانایی‌های تقویت شده در محاسبات ریاضی و نوشتن کد."
  },
  "yi-vision": {
    "description": "مدل وظایف بصری پیچیده، با توانایی‌های بالا در درک و تحلیل تصاویر."
  }
}
